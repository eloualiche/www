[{"id":0,"href":"/www/blog/posts/2024-03-TAQ-Consolidated-Data/","title":"Processing TAQ Consolidated Data","section":"Blog","content":"For a recent revision, I have had to dig into TAQ data. This is something relatively new to me, but I had to figure out some statistics out of the consolidated trade data. I did not want to use SAS because I do not have a PC running windows, and SAS for linux is very painful. So here is a method for getting annoying statistics from annoyingly large data.\nThe goal was to estimate the order imbalance volatility on the U.S. stock market. Order imbalance is defined as the difference between volume bought and sold scaled by the total volume exchanged:1\nOIBNUM: the number of buyer-initiated trades less the number of seller-initiated trades on day t. OIBSH: the buyer-initiated shares purchased less the seller-initiated shares sold on day t. OIBDOL: the buyer-initiated dollars paid less the seller-initiated dollars received on day t. It is too onerous (memory) to process everything at once, the goal of this guide is to show how to parallelize the process of working with this data stock by stock.\nData # For this I worked with the Trade and Quote (TAQ) data. Specifically, I downloaded consolidated trades data which is available from 1993 to 2014 directly from WRDS.2\nI downloaded the data year by year which took a little while given the size of each individual year (a gzipped extract in 2008 is above 26Gb and expands to 300Gb). Once downloaded, I reuploaded all the data to a s3 bucket where I have easy access to it.\nThe data includes a symbol for the stock id (there is a match table to permno on WRDS), a price, and a size.\nPreprocessing # I will process one year of data at a time \u0026mdash; technically, the algorithm for estimating whether a trade is a buy or sell could suffer from this, but I think the error is minimal here.\nThe preprocessing happens using a standard shell (bash or zsh).\nDefining variables # It is important to define a few variables for the shell\nThe relevant year: DATEY=2006 The number of processors available: nprocs=128 The memory available mem_alloc=512 (for example if you have 512G of ram available) A directory with lots of space (~1Tb) where you can expand and work with the data: TAQ_HOME=\u0026quot;/big_space_disk/\u0026quot; Download and expand the data # First I download the data from the s3 bucket using s5cmd as:3\n$ input_file=\u0026#34;TAQ_name_$DATEY\u0026#34; $ s5cmd cp s3://my-bucket/TAQ/$input_file.csv.gz $TAQ_HOME/ Then I expand the data; I take advantage of multicore expansion using pigz.\nFirst I peak at the data to check that the data has the correct columns and that the year is correct:\n$ pigz -cd | head -n 5 SYMBOL,DATE,TIME,PRICE,SIZE,G127,CORR,COND,EX A,2006-01-03,8:00:07,33.29,30000,0,0,U,T A,2006-01-03,8:08:01,33.29,8300,0,0,T,T A,2006-01-03,8:17:28,33.29,8600,0,0,T,T A,2006-01-03,9:30:22,33.4,96200,40,0,,N Once I have confirmed that I am looking at the right thing I expand the whole file:\n$ pigz -dc $TAQ_HOME/$input_file.csv.gz \u0026gt; $TAQ_HOME/taq_select.csv.gz For efficiency (untested), I have actually use the binaries from xsv4 to select only the columns from the file that I needed. Simply replace the previous command with:\npigz -cd $TAQ_HOME/$input_file.csv.gz | \\ xsv select \u0026#34;SYMBOL,DATE,TIME,PRICE,SIZE\u0026#34; \u0026gt; $TAQ_HOME/taq_select.csv Note that this is fairly slow and can take upwards of 20 minutes even reading the file from the ram disk.\nSort the data # In theory the data coming out of WRDS are already sorted by \u0026ldquo;SYMBOL\u0026rdquo;. But the strategy relies heavily on this step being accurate and it is always a good thing to learn how to use the very fancy unix sort function.\nWe want to split the data in chunks, one chunk for each symbol. It is a lot easier to do once the data is ordered by symbol!\nFirst we pipe the data without the header, then we use sort based on the first column and allow for parallel processing. The one thing to watch for is memory usage (this will eat pretty much of all your memory and get your job killed if you don\u0026rsquo;t watch it). So we define an upper bound for memory usage. Given the memory allocation defined above, we restrict sort to only use 80% of it:\nmem_for_sort=$(echo \u0026#34;${mem_alloc%G} * 0.8 / 1\u0026#34; | bc) # bc is the bash calculator /usr/bin/time tail -n +2 $TAQ_HOME/taq_select.csv | \\ sort -t, -k1,1 --buffer-size=\u0026#34;${mem_for_sort}G\u0026#34; --parallel=$nprocs --temporary-directory=$TAQ_HOME \u0026gt; $TAQ_HOME/taq_sorted.csv This can take a while. I have waited close to one hour for the largest files (128 cores, 490Gb of memory allocated).\nNote: you can clean up the non sorted file to save a little bit of space at this stage rm $TAQ_HOME/taq_select.csv\nSplit the data # Last of the preprocessing, we split the data in chunks: one chunk for each symbol/stock. Given the sorted nature of the data, this is a straightforward (I only spent a day figuring it out using chatGPT) application of awk\nFirst we make some room for the chunks by giving them their own directory\nTAQ_CHUNKS=\u0026#34;$TAQ_HOME/chunks/\u0026#34; mkdir -p $TAQ_CHUNKS Then we process the whole thing using awk\ncat $TAQ_HOME/taq_sorted.csv | \\ awk -v chunkDir=\u0026#34;$TAQ_CHUNKS\u0026#34; -F, \u0026#39; { if (last != $1) { if (last != \u0026#34;\u0026#34;) close(chunkDir \u0026#34;/chunk_\u0026#34; last \u0026#34;.csv\u0026#34;); last = $1; } print \u0026gt; (chunkDir \u0026#34;/chunk_\u0026#34; $1 \u0026#34;.csv\u0026#34;); }\u0026#39; The script reads the whole file line by line; it checks the first column (the \u0026ldquo;SYMBOL\u0026rdquo; column), if it is equal to the first column of the previous line, it appends the line to the file, if not it moves to create a new file. The created files are named based on the first column.\nThis process is sequential and can be quite slow (close to one hour for the largest file).\nProcessing of stock specific statistics in julia # We have close to 10,000 files in $TAQ_CHUNKS ready to be read one by one and processed. For this we are going to do some standard data processing in julia \u0026mdash; I compute OIB here, but this would for everything else that is at the stock-level.\nIf you have access to multiple cores, it makes sense to process this in paralle. It is fairly easy to implement; you still need to be careful not to trigger segfaults though.\nPreamble # My preamble is pretty standard and only use basic julia DataFrame stuff.\nusing CSV using DataFrames, DataFramesMeta using Dates, PeriodicalDates using Pipe: @pipe import ShiftedArrays: lag using Statistics import StatsBase: std @info Threads.nthreads() # usefule for parallelism later on # To ingest the command line parameter I pass to the script datey = ARGS[1] TAQ_CHUNKS = ARGS[2] # TAQ_CHUNKS=\u0026#34;/scratch.global/eloualic/taq/chunks\u0026#34; We are going to process each symbol one by one and store the statistics in a table.\nfile_list=readdir(TAQ_CHUNKS); n_files = length(file_list) df_oib_vol_array = Vector{Union{DataFrame, Nothing}}(nothing, n_files); Threads.@threads for i_f = 1:n_files # read the file for one stock df_taq_symbol = ingest_file(\u0026#34;$TAQ_CHUNKS/$file_in\u0026#34;; verbose=verbose) # create the trade sign flag df_taq_symbol = create_trade_sign!(df_taq_symbol) # create the order imbalance statistic df_oib = create_oib(df_taq_symbol) # get the volatility of the order imbalance df_oib_vol_array[i_f] = create_oib_vol(df_oib) end The most important step is how we read the file. Since this is happening inside a parallel loop, we need to make sure CSV.read only happens on a single thread.\nfunction read_file(file_in::AbstractString; verbose=false) df_taq_symbol = CSV.read(file_in, DataFrame, header=false, ntasks=1); rename!(df_taq_symbol, [:symbol, :date, :time, :price, :size]); end Next we follow Chordia et al. to estimate whether the trade is a buy or a sell order. Basically we compare the current price to previous prices (up to a lag of 5). This is the step that is the slowest when working with the whole dataset at a time.\nfunction create_trade_sign!(df_taq_symbol::DataFrame) @transform!(groupby(df_taq_symbol, :symbol), :l1_price=lag(:price), :l2_price=lag(:price, 2), :l3_price=lag(:price, 3), :l4_price=lag(:price, 4), :l5_price=lag(:price, 5)); @rtransform! df_taq_symbol @passmissing :trd_sgn = :price \u0026gt; :l1_price ? 1 : :price \u0026lt; :l1_price ? -1 : :price \u0026gt; :l2_price ? 1 : :price \u0026lt; :l2_price ? -1 : :price \u0026gt; :l3_price ? 1 : :price \u0026lt; :l3_price ? -1 : :price \u0026gt; :l4_price ? 1 : :price \u0026lt; :l4_price ? -1 : :price \u0026gt; :l5_price ? 1 : :price \u0026lt; :l5_price ? -1 : missing return df_taq_symbol end The other two functions are fairly straightforward and not particularly interesting\nfunction create_oib(df) #; to::TimerOutput=to) symbol_var=df[1,:symbol] dropmissing!(df, :trd_sgn) nrow(df)==0 \u0026amp;\u0026amp; return DataFrame(symbol=symbol_var, date=missing) # some do not have valid signed trades df_oib = @combine(groupby(df, [:date,:trd_sgn]), :oib_shr_sign=sum(:size), :oib_num_sign=length(:size)) |\u0026gt; (d -\u0026gt; @transform!(groupby(d, :date), :oib_shr_tot=sum(:oib_shr_sign), :oib_num_tot=sum(:oib_num_sign)) ) @transform!(groupby(df_oib, :date), :oib_shr_ratio=sum(:trd_sgn .* :oib_shr_sign) ./:oib_shr_tot, :oib_num_ratio=sum(:trd_sgn .* :oib_num_sign) ./:oib_num_tot, :symbol=symbol_var) return df_oib end function create_oib_vol(df) #; to::TimerOutput=to) symbol_var=df[1,:symbol] dropmissing!(df, :date) nrow(df)==0 \u0026amp;\u0026amp; return DataFrame(symbol=symbol_var, datem=missing, oib_shr_vol=missing, oib_num_vol=missing) df_oib_vol = unique(@rselect(df, :date, :datem=MonthlyDate(:date), :symbol, :oib_shr_ratio, :oib_num_ratio)) |\u0026gt; (d -\u0026gt; @combine(groupby(d, [:symbol, :datem]), :oib_shr_vol=std(:oib_shr_ratio), :oib_num_vol=std(:oib_num_ratio)) ) return df_oib_vol end I don\u0026rsquo;t run the code interactively (see the arguments passed above). The command I pass reads:\n$ julia -t $nprocs import_taq_chunks.jl $DATEY $TAQ_CHUNKS \u0026amp;\u0026gt; import_taq_chunks.log.jl SLURM Specifics # If you are running on the job on a cluster with the slurm scheduler, I have attached the commands I have used to make my life easier.\nChordia, Roll, Subrahmanyam (2002): Order imbalance, liquidity, and market returns, Journal of Financial Economics: 65\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI could not find the relevant postgres database for the product, so I processed everything through webqueries. The product is taq_common, library is taq, and file is ct.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ns5cmd is faster than s3cmd, but in the grand scheme of things here this is not going to matter very much.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI tried installing the more recent qsv but could not compile it properly on the Minnesota Supercomputing Institute MSI cluster.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":1,"href":"/www/blog/posts/2024-03-ST-and-Julia/","title":"Sublime Text and Julia IDE","section":"Blog","content":"Sometimes, I am asked how to set up a simple julia IDE for people who are already using Sublime Text. It is simple in theory but many things can go wrong, so I thought this document could be useful.\nI try to provide step by step instructions as much as possible. Feel free to email me if some of the steps were not as clear as you would have liked.\nN.B.\nThere might be better ways to have a julia IDE (see VSCode with LSP). I happen to like Sublime, it is simpler and faster than VSCode (but I am also an emacs person). Also note that the same thing would apply for R (just change a few paths here and there). This guide was written on 2024-03-xx for Sublime Text 4 and julia 1.10.1\n1. Prerequisite # The \u0026ldquo;required\u0026rdquo; software for this guide are: julia, Sublime Text, and a Terminal application called iterm2.\nFirst, I would recommend to install (optional but recommended) a nicer terminal application than the built-in macos terminal:\nDownload iterm2.\nThis is not strictly necessary but iterm2 has some nice feature that make it work nicely with the Sublime setup here. There are other good terminal applications for macos (e.g. kitty) but I am not as familiar with those. Open the iterm2 application which should be in the application folder (note I will use the words iterm2 and the terminal interchangeably (technically they are not quite the same thing but it won\u0026rsquo;t matter). Download Sublime Text 4 and follow the instructions to install.\nDownload julia and follow the instructions to install.\nAs I am writing this, you can use juliaup to install julia by copying and pasting in your terminal the following: curl -fsSL https://install.julialang.org | sh This allows you to keep your version of julia up to date (this might be a bad thing if you have old code and are not templating packages) Or (simpler imho) download the latest current stable release and install it depending on your platform For example for macos with Apple Silicon download the dmg and install it in your application folder 2. Getting julia to work! # 2.1 Basic installation # If julia is in your application folder, there are two ways to start a julia session.\nDouble click on the julia icon: this opens the macos terminal application (not iterm2) and starts julia Open the terminal (I am assuming iterm2 from now on) and type or paste the path of the julia application binary. For julia 1.10.1 the binary will likely at /Applications/Julia-1.10.app/Contents/Resources/julia/bin/julia If you are working with version 1.XX (where XX is a different number) the path will likely be /Applications/Julia-1.XX.app/Contents/Resources/julia/bin/julia 2.2 Adding julia to your path # Do you need it? # If you have installed julia using juliaup (see section 1 above), the julia application was automatically added to your PATH.1 I believe this means the next step is not necessary. To see whether you should skip the next step type julia inside of iterm2. If julia opens, you are in business, skip 2.2 and go to section 3. If there is some error or julia does not open, follow the instructions in the next section 2.2.\nAdding julia to the path # Typing the full julia path can get annoying pretty quickly, so we will add the directory to the PATH for the terminal (technically for the shell). To make this permanent we are going to edit a special file which is read everytime you start your terminal.\nOn macos the file is .zshrc since the default shell is zsh; this is a configuration file. On other machine the file might be .bashrc if your default shell is bash.\nTo edit this file we need a text editor. Any will do; for example you could use textedit and enter the following at the terminal: open -a TextEdit ~/.zshrc This tells textedit to open the zsh configuration file which is located on your home directory under ~2 You could also use Sublime Text that you just opened; the following should work if it installed properly in the Applications folder: /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl ~/.zshrc\nNow we need to edit this file by adding julia to the path. We can simply add this line:\nexport PATH=$PATH:/Applications/Julia-1.10.app/Contents/Resources/julia/bin This concatenates your path with what was already in it ($PATH) and the directory where the julia binary is. If you are working with a version different than 1.10 then adjust the line for 1.XX as: export PATH=$PATH:/Applications/Julia-1.XX.app/Contents/Resources/julia/bin\nSave the file. Close the window. Restart the terminal (iterm2). Now you should be able to start julia in the terminal by typing julia from anywhere.\n3. Getting Sublime Text to play nice with julia # Sublime text is an editor that relies on packages for added functionality. So next, we will download the necessary packages to get a setup that will let you work with julia from sublime text.\n3.1. Installing Sublime packages # First install the package that can install other packages: that is package control. The instructions to install it are:\nOpen the command palette (cmd+shift+p on macos) Type Install Package Control, press enter Then install the Julia-sublime package similary:\nOpen the command palette (cmd+shift+p on macos) Type Package Control: Install, press enter Then a dropdown menu will show and type julia to search for the julia package, type enter to install it. Last install the SendCode package\nOpen the command palette (cmd+shift+p on macos) Type Package Control: Install, press enter Then a dropdown menu will show and type SendCode to search for the SendCode package, type enter to install it. 3.2 Setting up Sublime packages # Settings of SendCode Open the settings of sendcode: open the command palette (cmd+shift+p on macos), type SendCode settings, and enter You should be dropped into a new window with two files (one on each side). Edit the one on the right which is the one with your personal settings (the one on the left has the general settings). Its name is SendCode.sublime-settings. If you are working with iterm2 copy and paste the following: { \u0026#34;auto_advance\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, \u0026#34;julia\u0026#34;: { \u0026#34;bracketed_paste_mode\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, }, \u0026#34;r\u0026#34;: { \u0026#34;bracketed_paste_mode\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, }, } Keybindings SendCode Open the settings of sendcode: open the command palette (cmd+shift+p on macos), type SendCode key bindings, and enter You should be dropped into a new window with two files (one on each side). Edit the one on the right which is the one with your personal settings (the one on the left has the general settings). This time do not remove existing keybindings as they might be useful stuff. You should add the following to make sure sending lines or highlighted content to be sent to iterm2. { \u0026#34;keys\u0026#34;: [\u0026#34;super+enter\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;send_code\u0026#34;, \u0026#34;context\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;selector\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;equal\u0026#34;, \u0026#34;operand\u0026#34;: \u0026#34;source\u0026#34; } ] }, { \u0026#34;keys\u0026#34;: [\u0026#34;ctrl+enter\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;send_code\u0026#34;, \u0026#34;context\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;selector\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;equal\u0026#34;, \u0026#34;operand\u0026#34;: \u0026#34;source\u0026#34; } ] }, Feel free to change the key bindings for example if you want Cmd-s to send to iterm2 you would replace \u0026ldquo;super+enter\u0026rdquo; by \u0026ldquo;super+s\u0026rdquo;. You should be good to go. Create a test.jl file. Open a terminal session and start julia on the side. select 1+1 in sublime text and press Cmd+Enter at the same time. It should be sending to the terminal.\nYour path is essentially a set of places where the terminal looks for software. So if the directory of julia gets added to the path, the terminal is aware of the julia application and you can type directly $ julia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n~ represents what is known as your home directory. The actual address is /Users/yourname/. You can find it by doing in the terminal: cd ~ to change directory to the home directory, and then pwd to print the directory you are currently in.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":2,"href":"/www/blog/posts/2023-07-DataFrames-and-datatable/","title":"From R data.table to julia DataFrames.jl","section":"Blog","content":" Introduction # This is meant as a resource for people trying to move between R and julia who are using data.table on the one hand and DataFrames.jl on the other. I have gathered function I tend to use frequently or that I find frustrating to look for when I need them. There are probably glaring omissions. Feel free to open an issue here.\nResources # I will mostly follow the excellent stata2r as a template. You can also have a look at some of the mappings in the DataFrames.jl documentation I have found this guide of data.table by Andrew Brooks very useful. A word of warning # Missing Data. Dealing with missing data in julia requires to be explicit as most functions will return a missing value if an array includes a missing element. Some functions will error. I will try to point out the equivalence with the R code but be aware that the equivalence might not be always be strictly the same if you implement it. I show some of the examples on the Freedman dataset from the car package in R. Need improvement. A few specific sections could use some user inputs as the julia solutions were less than ideal: Leads and lags; Dates; Complex merges Issues # This is a first draft and there might be a few mistakes throughout the document. I am not a professional and I probably picked up bad habits here and there. Email me at eloualic@umn.edu File an issue on gitlab here if you want to start a dicussion or have ideas of things to add/change Installation # Installation can sometime be challenging. This should not be an issue in julia here. We will mostly use the base DataFrames package and the convenient macros in the DataFramesMeta package. To read in data we will use the CSV package while julia supports many different file formats (see FileIO.jl) Installation for data.table can be tricky especially if you want to benefit from the multicore features. I recommend that you look at the installation wiki for more details. import Pkg Pkg.add(\u0026#34;DataFrames\u0026#34;) Pkg.add(\u0026#34;DataFramesMeta\u0026#34;) # Load the packages using DataFrames using DataFramesMeta install.packages(\u0026#34;data.table\u0026#34;) # latest development version that has passed all tests: data.table::update_dev_pkg() # Load the package library(data.table) import Pkg Pkg.add(\u0026#34;DataFrames\u0026#34;) Pkg.add(\u0026#34;DataFramesMeta\u0026#34;) # Load the packages using DataFrames using DataFramesMeta install.packages(\u0026#34;data.table\u0026#34;) # latest development version that has passed all tests: data.table::update_dev_pkg() # Load the package library(data.table) We will also use other packages to load auxiliary datasets, download data etc. I use the pipe macro in julia and the magrittr package in R to compose commands (though both packages have some amount of chaining built-in)\n# Install the packages Pkg.add(\u0026#34;CSV\u0026#34;) Pkg.add(\u0026#34;ShiftedArrays\u0026#34;) # lead/lag operators Pkg.add(\u0026#34;HTTP\u0026#34;) # download utilities Pkg.add(\u0026#34;RDatasets\u0026#34;) Pkg.add(\u0026#34;Pipe\u0026#34;) # pipes # Install the packages install.packages(\u0026#34;car\u0026#34;) # RDataset install.packages(\u0026#34;magrittr\u0026#34;) # pipes install.packages(\u0026#34;statar\u0026#34;) # stata-style data utilities install.packages(\u0026#34;lubridate\u0026#34;) # date utilities # Load the packages using HTTP using CSV using RDatasets using Pipe using ShiftedArrays using Dates # We will need some statistical function from the Base package import Statistics: mean, median, quantile # Load the packages library(car) library(magrittr) library(statar) library(lubridate) File I/O # Reading Data # I am using the flight dataset to run most of the examples. This assumes your data is in a csv format.\nThere are options in both languages to read from more efficient formats like parquet. I have found that csv is both fast and idioproof and lends itself to quick manipulation on the shell if I need to do something quickly.\nIn julia, the CSV.jl package does not allow to read directly from a url but we can use the HTTP.jl package to download the file. In R, you can directly read the dataset from an url using fread in data.table. # Flights data url_flights = \u0026#34;https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\u0026#34; url_get = HTTP.get(url_flights); dat = CSV.read(url_get.body, DataFrame) # If the dataset is compressed, the data is expanded to /tmp (see this [issue](https://github.com/JuliaData/CSV.jl/issues/988)) # If you are limited by how much to write on `/tmp` (HPC) then use dat = CSV.read(\u0026#34;file.csv.gz\u0026#34;, DataFrame, buffer_in_memory=true) # Freedman data dat_missing = RDatasets.dataset(\u0026#34;car\u0026#34;, \u0026#34;Freedman\u0026#34;) # Flights data url_flights = \u0026#34;https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\u0026#34; dat = fread(url_flights) # In fread you can choose to which temp folder to write intermediary files using `tmpdir` # Note: this is different from the option offered in `julia` fread(\u0026#34;file.csv.gz\u0026#34;, tmpdir=\u0026#34;~/tmp\u0026#34;) # Freedman data dat_missing = data.table(Freedman) # load and convert to data.table Writing Data # To write the file we use a similar function. It is also possible to save the file with compression Similarly data.table provides a write function with optional compression CSV.write(\u0026#34;./data.csv\u0026#34;, dat) CSV.write(\u0026#34;./data.csv.gz\u0026#34;, dat; compress=true) If you want to set up a different compression algorithm (faster or more efficient) use TranscodingStreams.jl with the appropriate codec. For example if you want to use zst you would do\nPkg.add(\u0026#34;CodecZstd\u0026#34;) using CodecZstd open(ZstdCompressorStream, \u0026#34;./data.csv.zst\u0026#34;, \u0026#34;w\u0026#34;) do stream CSV.write(stream, dat) end # similarly to read it back dat = open(ZstdDecompressorStream, \u0026#34;./data.csv.zst\u0026#34;, \u0026#34;r\u0026#34;) do stream CSV.read(stream, DataFrame) end fwrite(dat, \u0026#34;./data.csv\u0026#34;) fwrite(dat, \u0026#34;./data.csv.gz\u0026#34;, compress=\u0026#34;gzip\u0026#34;) # with compression (Benchmarks) # I would like to include a benchmark for one large file and compare csv intake to parquet.\nInspecting the dataset # This is before we start filtering, collapsing, or merging the data.\nSorting # It is important to be able to sort rows. What are the most delayed flights, what about the most delayed flight on a specific day?\nNote that the code changes the order \u0026ldquo;in-place\u0026rdquo; as it changes the dataset itself.\nThe most basic task is to sort some columns with respect to a specific variable Similarly data.table provides a write function with optional compression sort!(dat, :air_time) sort!(dat, [:air_time, :dest]) sort!(dat, :air_time; rev=true) sort!(dat, [order(:air_time, rev=true), :dest]) # if you do not want to change the dataset in place sort(dat, :air_time) setorder(dat, air_time) setorder(dat, air_time, dest) setorder(dat, -air_time) setorder(dat, -air_time, dest) # if you do not want to change the dataset in place dat[ order(air_time)] # etc. # To reorder a dataset programmatically use the `setorderv` function col = \u0026#34;air_time\u0026#34; setorderv(dat, col) If we want to reorder columns (rather than rows)\nselect!(dat, [:month, :day], Not([:month, :day])) setcolorder(dat, c(\u0026#34;month\u0026#34;, \u0026#34;day\u0026#34;)) Renaming # Renaming does modify the dataset but it does not alter its data so we include it here.\nThis is where I start leaning on the macros from DataFramesMeta.jl Similarly data.table provides a write function with optional compression @rename!(dat, :new_arr_delay = :arr_delay) @rename!(dat, :new_carrier = :carrier, :new_origin = $\u0026#34;origin\u0026#34;) @rename(dat, :new_arr_delay = :arr_delay) # not in place rename!(x -\u0026gt; replace(x, \u0026#34;arr_\u0026#34; =\u0026gt; \u0026#34;arrival_\u0026#34;), dat) # use the base DataFrames.jl function here setnames(dat, \u0026#34;new_arr_delay\u0026#34;, \u0026#34;arrival_delay\u0026#34;) setnames(dat, c(\u0026#34;carrier\u0026#34;,\u0026#34;origin\u0026#34;), c(\u0026#34;new_carrier\u0026#34;,\u0026#34;new_origin\u0026#34;)) setnames(dat, gsub(\u0026#34;arr_\u0026#34;, \u0026#34;arrival_\u0026#34;, names(dat))) Summary Statistics # describe(dat) describe(dat, :arr_delay) describe(dat, :min, :detailed, cols=:arr_delay) sum_up(dat) # from statar package sum_up(dat, arr_delay) sum_up(dat, arr_delay, d = TRUE) Tabulations # summary_var = :carrier # or [:carrier, :origin] @pipe dat |\u0026gt; groupby(_, summary_var) |\u0026gt; combine(_, nrow =\u0026gt; :Freq, proprow =\u0026gt; :Percent) |\u0026gt; @transform(_, :Cum = cumsum(:Percent)) tab(dat, carrier) # from statar package tab(dat, carrier, origin) # data.table version dat[, .N, by = .(carrier, origin)][, `:=`(Percent=100*N/nrow(dat), Cum=100*cumsum(N)/nrow(dat)) ][] Filtering # Subsetting rows # On the flights data # There are multiple options for filtering; this is where I start leaning on the macros from DataFramesMeta.jl In data.table filtering is not in place and you will need to assign the dataset (to itself) for the changes to propagate. dat[1:200, :] subset(dat, :day =\u0026gt; x -\u0026gt; x .\u0026gt; 5 .\u0026amp; x .\u0026lt; 10) # from dataframes base @subset(dat, :day .\u0026gt; 5 .\u0026amp; :day .\u0026lt; 10) # note the `.` for broadcasting @rsubset(dat, :day \u0026gt; 5 \u0026amp; :day \u0026lt; 10) # note the `r` for change by row @rsubset!(dat, :day \u0026gt; 5 \u0026amp; :day \u0026lt; 10) # change in place @rsubset(dat, :origin == \u0026#34;LGA\u0026#34;) @rsubset(dat, occursin(r\u0026#34;^LG\u0026#34;, :origin)) @rsubset(dat, :month ∈ [3, 4, 11, 12]) @rsubset(dat, :origin ∈ [\u0026#34;JFK\u0026#34;, \u0026#34;LGA\u0026#34;]) @rsubset(dat, :month != 1) dat[1:200] dat[day \u0026gt; 5 \u0026amp; day \u0026lt; 10] # filtering only dat = dat[day \u0026gt; 5 \u0026amp; day \u0026lt; 10] # filtering and reassigning dat[origin==\u0026#34;LGA\u0026#34;] dat[origin %like% \u0026#34;^LG\u0026#34;] dat[month %in% c(3,4,11,12)] dat[origin %chin% c(\u0026#34;JFK\u0026#34;,\u0026#34;LGA\u0026#34;)] # %chin% is a fast %in% for characters dat[month!=1] On the Freedman data (with missing values) # In this case we need to be careful on how we deal with missing data. Note that to find the missings julia uses the isequal function (because missing==missing returns missing).\nsubset(dat_missing, :Population =\u0026gt; x -\u0026gt; x .\u0026lt; 1000; skipmissing=true) @rsubset(dat_missing, :Population .\u0026lt; 1000) # treats missing values as false by default @rsubset(dat_missing, isequal(:Population, missing) ) dat_missing[ population \u0026lt; 1000 ] dat_missing[is.na(population)] Dropping duplicate or missing values # Drop duplicate values # unique(dat; keep=:first) # default unique!(dat; keep=:first) # in place unique(dat; keep=:noduplicates) # :last also an option unique(dat, [:month, :day, :carrier]) unique(dat) dat = unique(dat) unique(dat, by = c(\u0026#34;month\u0026#34;, \u0026#34;day\u0026#34;, \u0026#34;carrier\u0026#34;)) Drop missing values # dropmissing(dat_missing) dropmissing!(dat_missing) # in place dropmissing(dat_missing, :Population) dropmissing(dat_missing, [:Population, :Density]) # if the column type still include missing values convert the array to non missing types disallowmissing(dat_missing) disallowmissing(dat_missing, :Density) na.omit(dat_missing) dat_missing = na.omit(dat_missing) dat_missing[!is.na(population)] dat_missing[!is.na(population) \u0026amp; !is.na(density)] Selecting columns # # select columns select(dat, :month, :day, :carrier) select!(dat, :month, :day, :carrier) # in place select(dat, \u0026#34;month\u0026#34;, \u0026#34;day\u0026#34;, \u0026#34;carrier\u0026#34;) # also works select(dat, r\u0026#34;_delay\u0026#34;) select(dat, .!(eltype.(eachcol(dat)) .\u0026lt;: AbstractString) ) select(dat_missing, (eltype.(eachcol(dat_missing)) .\u0026lt;: Union{Missing, Int}) ) # if some columns include missing # removing select columns select(dat, Not([:origin, :dest])) select!(dat, Not([:origin, :dest])) # in place # select columns dat[, .(month, day, carrier)] dat = dat[, .(month, day, carrier)] # \u0026#34;in place\u0026#34; dat[, c(\u0026#34;month\u0026#34;, \u0026#34;day\u0026#34;, \u0026#34;carrier\u0026#34;)] # same but programmatic dat[, .SD, .SDcols=patterns(\u0026#34;*_delay\u0026#34;)] # keep columns by matching dat[, .SD, .SDcols=!is.character] # keep columns by type # removing select columns dat[, -c(\u0026#34;origin\u0026#34;, \u0026#34;dest\u0026#34;)] dat[, c(\u0026#34;origin\u0026#34;, \u0026#34;dest\u0026#34;) := NULL] # same, but in-place Rows and columns # @select(@rsubset(dat, :origin==\u0026#34;LGA\u0026#34;), :month, :day, :carrier) @pipe dat |\u0026gt; @rsubset(_, :origin==\u0026#34;LGA\u0026#34;) |\u0026gt; @select(_, :month, :day, :carrier) dat[origin==\u0026#34;LGA\u0026#34;, .(month, day, carrier)] Creating/modifying variables # Basic operations # @transform!(dat, :tot_delay = :dep_delay + :arr_delay) @rtransform!(dat, :segment = :origin * :dest) # rowwise operation # Programmatic version x = \u0026#34;dep_delay\u0026#34;; y = \u0026#34;arr_delay\u0026#34;; z = \u0026#34;tot_delay\u0026#34;; @transform!(dat, $z = $x + $y) # Conditional modification dat[dat.month.==9, :distance] = dat[dat.month.==9, :distance] .+ 1; dat[1:2, :air_time] .= 0; # Or with missing values dat_missing[isequal.(dat_missing.Population, missing), :City] .= \u0026#34;NOPOP\u0026#34;; dat[, tot_delay := dep_delay + arr_delay] dat[, segment := paste0(origin, dest) ] # Programmatic version x = \u0026#34;dep_delay\u0026#34;; y = \u0026#34;arr_delay\u0026#34;; z = \u0026#34;tot_delay\u0026#34; dat[, c(z) := get(x) + get(y) ] # Conditional modification dat[month==9, distance := distance + 1] dat[1:2, origin := \u0026#34;OBS\u0026#34;] # Or with missing values dat_missing[is.na(population), City := \u0026#34;NOPOP\u0026#34;] Grouped operations # @pipe dat |\u0026gt; groupby(_, :carrier) |\u0026gt; @transform!(_, :avg_arr_delay = mean(:arr_delay)) # in place @pipe dat |\u0026gt; groupby(_, :carrier) |\u0026gt; @combine(_, :avg_arr_delay = mean(:arr_delay)) dat[, avg_arr_delay := mean(arr_delay), by=carrier] dat[, .(avg_arr_delay = mean(arr_delay, na.rm=T)), by=carrier] # collapse see aggregation section below Leads and lags # Standard leads and lags # I work with shifts on dates here but the dataset is a full panel with consecutive dates so there is nothing special about the dates variable per-se.\nIt is easier to see this on a smaller dataset. So I aggregate the data to get the total monthly flights out of each origin airport (see last section).\nFor leads and lags on arrays, I use the ShiftedArrays package which works fine for standard operations (read: as long as you are not dealing with dates). For standard leads and lags, it is faster to use the built-in shift function from data.table. dat_shift = combine( groupby(dat, [:origin, :month]), nrow =\u0026gt; :N) sort!(dat_shift, [:origin, :month]) @transform!(groupby(dat_shift, :origin), :growth = :N ./ ShiftedArrays.lag(:N, 1)) @transform!(groupby(dat_shift, :origin), :growth_since_first = :N ./ :N[1] ) # The following is probably not optimal; here are two versions @pipe dat_shift |\u0026gt; groupby(_, :origin) |\u0026gt; @subset(_, 5 ∈ :month) |\u0026gt; # this errors if month 5 is missing in a group groupby(_, :origin) |\u0026gt; @transform(_, :growth_since_may = :N ./ :N[:month.==5]) for subdf in groupby(dat_shift, :origin) if 5 ∈ subdf.month @transform!(subdf, :growth_since_may = :N ./ :N[:month.==5]) end end dat_shift = dat[, .N, by = .(origin, month)] setorder(dat_shift, origin, month) dat_shift[, growth := N/shift(N, 1), by = origin] dat_shift[, growth_since_first := N/N[1], by = origin] dat_shift[, growth_since_may := N/N[month==5], by = origin] dat_shift[, growth_since_may := .SD[[\u0026#34;N\u0026#34;]]/.SD[month==5][[\u0026#34;N\u0026#34;]], .SDcols = c(\u0026#34;N\u0026#34;, \u0026#34;month\u0026#34;), by = origin] The case of dates # Dates are messy (imho). Lagging a variable by three months in a monthly panel does not necessarily translate into shifting the data by 3 indices (if the panel is unbalanced for example). The correct date function should check that \u0026ldquo;shifting\u0026rdquo; by three months in April corresponds to January and not December (if January is missing).\n@rtransform!(dat, :date = Date(:year, :month, :day) ) # Including time @rtransform!(dat, :date_time = DateTime(:year, :month, :day, :hour) ) @rtransform!(dat, :date_y = year(:date)) @rtransform!(dat, :f7d_date = :date + Dates.Day(7)) @rtransform!(dat, :l3m_date = :date - Dates.Month(3)) # Make a date variable using data.table built-in IDate dat[, date := as.IDate(paste(year, month, day, sep=\u0026#39;-\u0026#39;))] # It is usually faster to use lubridate parser dat[, date := parse_date_time2(paste(year, month, day, sep=\u0026#39;-\u0026#39;), \u0026#34;Y-m-d\u0026#34;)] dat[, date_time := parse_date_time2(paste(year, month, day, hour, sep=\u0026#39;-\u0026#39;), \u0026#34;Y-m-d-H\u0026#34;)] dat[, date_y := year(date)] # extract year dat[, f7d_date := date + days(7) ] # date in 7 days dat[, l3m_date := date - months(3) ] # date three months ago Once we know how to lag dates, we would like to answer questions such as: what was the average flight delay for each origin airport three months ago compared to today? We will work with the aggregate delays by origins.\nIn julia, the ShiftedArrays package does not support dates (See this post on discourse and this issue)\nThis is one of the most annoying thing when working with dates and panel data in julia. I have found that PanelShift.jl solves the problem but it is still in version 0.1.1 and it is unclear how many updates it is receiving. What is nice with julia is that you can simply loop over the data and do exactly what you want to do.\nIn R, I use the utility tlag and tlead from statar which lags based on date intervals. @rtransform!(dat, :date = Date(:year, :month, :day) ) dat_shift = @combine(groupby(dat, [:origin, :date]), :arr_delay = mean(:arr_delay) ) # I could not find a built-in function, but julia is amenable to loops dat_shift.l3m_arr_delay = Array{Union{Missing,Float64}}(undef, nrow(dat_shift)); for subdf in groupby(dat_shift, :origin) for date_iter in subdf.date idx = isequal.(subdf.date, date_iter - Dates.Month(3)) if (sum(idx)==1) subdf[ subdf.date .== date_iter, :l3m_arr_delay] .= subdf[idx, :arr_delay] end end end # sort(dat_shift, [:origin, :date]) # using PanelShift @transform!(groupby(dat_shift, :origin), :l3m_arr_delay = tlag(:date, :arr_delay, Month(3) ) ) panellag!(dat_shift, :origin, :date, :arr_delay, :l3m_arr_delay, Month(3)) dat_shift = dat[, .(arr_delay = mean(arr_delay, na.rm=T)), by = .(origin, date=parse_date_time2(paste(year, month, day, sep=\u0026#34;-\u0026#34;), \u0026#34;Y-m-d\u0026#34;))] dat_shift[, l3m_arr_delay := tlag(arr_delay, n=months(3), time=date), by = .(origin) ] # setorder(dat_shift, origin, date) Advanced examples # Applying functions to multiple variables # Loops: if you have to use loops for convenience, data.table provides set which allows to change values withouth the overhead of data.table. The syntax is of the form set(dat, i, j,value), where i is the row index, and j the column index (or name). # Loops for col in (:tot_delay, :dep_delay) dat[1:10, col] = - dat[1:10, col] end # Control flows @rtransform!(dat, :arr_delay_penaly = ifelse(:arr_delay\u0026gt;12, 1, -1) ) @rtransform!(dat, :arr_delay_penaly = ifelse( # no case function in julia :arr_delay\u0026gt;=15, 3, ifelse(:arr_delay\u0026gt;=6, 2, ifelse(:arr_delay\u0026gt;=0, 1, 0) ) ) ) # Modify multiple variables at the same time (same function) cols = [:origin, :dest] transform!(dat, cols .=\u0026gt; (x -\u0026gt; x .* \u0026#34;Airport\u0026#34;) .=\u0026gt; cols) # Apply multiple functions to one variable list_fun = [mean, median, x-\u0026gt;quantile(x, 0.25)] transform(dat, :dep_delay .=\u0026gt; list_fun .=\u0026gt; [:delay_mean, :delay_median, :delay_q25]) # Apply multiple functions to multiple variables (automatic renaming) cols = [:dep_delay :arr_delay] res_cols = kron([\u0026#34;mean_\u0026#34;, \u0026#34;median_\u0026#34;, \u0026#34;q25_\u0026#34;], string.(cols)) transform(dat, cols .=\u0026gt; list_fun .=\u0026gt; res_cols) # Function of multiple variables (by rows) ratio_airtime(x::NamedTuple) = (x[1] /(x[1]+x[2])) @rtransform! dat :frac_air = ratio_airtime(AsTable([:air_time, :tot_delay])) ratio_airtime(x, y) = (x /(x+y)) transform(dat, [:air_time, :tot_delay] =\u0026gt; ByRow((ratio_airtime)) =\u0026gt; :frac_air) # Loops for (j in c(\u0026#34;tot_delay\u0026#34;, \u0026#34;dep_delay\u0026#34;)){ # (faster) loops set(dat, 1:10, j=j, value=-dat[1:10][[j]]) } # Control flows dat[, arr_delay_penaly := fifelse(arr_delay\u0026gt;12, 1, -1) ] dat[, arr_delay_penaly := fcase(arr_delay\u0026gt;=15, 3, arr_delay\u0026gt;=6, 2, arr_delay\u0026gt;=0, 1, default = 0) ] # Modify multiple variables at the same time cols = c(\u0026#34;origin\u0026#34;, \u0026#34;dest\u0026#34;) dat[, (cols) := lapply(.SD, \\(x) paste(x,\u0026#34;Airport\u0026#34;)), .SDcols = cols] # Apply multiple functions to one variable 3b736f67aa239ba993b9674f5b5496bc)) list_fun = function(x) list(mean(x), median(x), quantile(x, 0.25)) dat[, c(\u0026#34;delay_mean\u0026#34;, \u0026#34;delay_median\u0026#34;, \u0026#34;delay_q25\u0026#34;) := sapply(.SD, list_fun), .SDcols = c(\u0026#34;dep_delay\u0026#34;)] # Apply multiple functions to multiple variables dat[, as.list(unlist(lapply(.SD, list_fun))), .SDcols = c(\u0026#34;dep_delay\u0026#34;, \u0026#34;arr_delay\u0026#34;) ] #\u0026lt;1\u0026gt; # other method melt(dat, measure.vars=c(\u0026#34;dep_delay\u0026#34;, \u0026#34;arr_delay\u0026#34;) )[ , sapply(.SD, list_fun), .SDcols = c(\u0026#34;value\u0026#34;), by = .(variable)] # Function of multiple variables dat[, tot_delay := rowSums(.SD), .SDcols=patterns(\u0026#39;*_delay\u0026#39;)] ratio_airtime = function(air, tot) (air /(air+tot)) # dat[, frac_air := ratio_airtime(air_time, tot_delay) ] dat[, frac_air := ratio_airtime(air_time, tot_delay), by=.I] # row-wise operation See caveat here Applying complex functions # # Regressions by groups # using FixedEffectModels for subdf in groupby(dat, [:year, :month]) reg_res = reg(subdf, @formula(tot_delay ~ air_time)) subdf[:, :β] .= coef(reg_res)[2] subdf[: , :σ] .= sqrt.(vcov(reg_res)[2,2]) end select(dat, [:year, :month, :β, :σ]) |\u0026gt; unique # Regressions by groups dat_reg = dat[, .( { y = as.matrix(.SD[[\u0026#34;tot_delay\u0026#34;]]) x = as.matrix(cbind(1, .SD[[\u0026#34;air_time\u0026#34;]]) ) reg_res = lm.fit(x, y) b = coefficients(reg_res)[2] se = sqrt(sum(reg_res[[\u0026#34;residuals\u0026#34;]]^2) / var(.SD[[\u0026#34;air_time\u0026#34;]]) ) / .N c(b,se) }, seq(1,2) ), by = .(year, month) ] dcast(dat_reg, year + month ~ V2, value.var=\u0026#34;V1\u0026#34;) # anticipating on reshape section Aggregating # @combine(dat, :mean_dep_delay = mean(:dep_delay)) @combine(dat, :mean_dep_delay = mean(:dep_delay), :mean_arr_delay = mean(:arr_delay)) combine(dat, [:dep_delay, :arr_delay] .=\u0026gt; mean .=\u0026gt; [:mean_dep_delay, :mean_arr_elay]) @combine(dat, $AsTable = mean.([:dep_delay, :arr_delay])) @combine(dat, $([:dep_delay, :arr_delay] .=\u0026gt; mean) ) # More complex but useful for quantiles @combine(dat, $AsTable = NamedTuple( (^(:q25_dep_delay), ^(:q75_dep_delay)) .=\u0026gt; (quantile(:dep_delay, [0.25, 0.75])) ) ) dat[, mean(dep_delay)] # returns a scalar dat[, .(mean_ddel = mean(dep_delay))] # returns a data.table dat[, .(mean_ddel=mean(dep_delay), mean_adel=mean(arr_delay))] dat[, lapply(.SD, mean), .SDcols=c(\u0026#39;arr_delay\u0026#39;,\u0026#39;dep_delay\u0026#39;)] # More than one variable dat[, as.list(quantile(.SD, c(.25, .75), na.rm = TRUE)), .SDcols=\u0026#34;dep_delay\u0026#34; ] # and merge back ... Reshaping # Wide to long # Julia uses stack for going from wide to long. In data.table, we use the built-in tool melt for going from wide to long. # It is easier if we give all the flights a unique identifier @transform!(dat, :uid = 1:nrow(dat)) stack(dat, [:dep_delay, :arr_delay] ) stack(dat, r\u0026#34;_delay\u0026#34;) dat_long = stack(dat, [:dep_delay, :arr_delay], [:uid, :carrier, :origin, :dest]) # It is easier if we give all the flights a unique identifier dat[, uid := seq(1, .N) ] melt(dat, measure=c(\u0026#34;dep_delay\u0026#34;, \u0026#34;arr_delay\u0026#34;)) melt(dat, measure=patterns(\u0026#39;_delay\u0026#39;)) dat_long = melt(dat, measure=c(\u0026#34;dep_delay\u0026#34;, \u0026#34;arr_delay\u0026#34;), id.vars=c(\u0026#34;uid\u0026#34;, \u0026#34;carrier\u0026#34;, \u0026#34;origin\u0026#34;, \u0026#34;dest\u0026#34;)) Long to wide # Julia uses unstack for going from long to wide. In data.table, we use the built-in tool dcast for going from long to wide. # We start with the long data from above dat_wide = unstack(dat_long) # If you only want to keep the id \u0026amp; *_delay cols unstack(dat_long, :uid, :variable, :value) # We start with the long data from above dat_wide = dcast(dat_long, ... ~ variable) # If you only want to keep the id \u0026amp; *_delay cols dcast(dat_long, uid ~ variable) Merging # Basic merge # # Load second dataset dat_airports = CSV.read( HTTP.get(\u0026#34;https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv\u0026#34;).body, DataFrame) # Inner join innerjoin(dat, dat_airports, on=:dest =\u0026gt; :faa) # if the datasets share a common name for the merge variable @rename!(dat_airports, :dest=:faa) innerjoin(dat, dat_airports, on=:dest) # _join also have an in-place components that updates the first dataframe argument innerjoin!(dat, dat_airports, on=:dest) # with missing values innerjoin(dat, dat_airports, on=:dest; matchmissing=:error) # Other types of merge # Left join leftjoin(dat, dat_airports, on=:dest) leftjoin(dat, dat_airports, on=:dest, source=\u0026#34;_merge\u0026#34;) # stata style merge info # if there are missing values in the merge columns leftjoin(dat, dat_airports, on=:dest, matchmissing=:notequal) # # Right join rightjoin(dat, dat_airports, on=:dest) # Outer join outerjoin(dat, dat_airports, on=:dest) # Semi join (filtering) semijoin(dat, dat_airports, on=:dest) # Anti join antijoin(dat, dat_airports, on=:dest) # Cross join crossjoin(unique(select(dat, :origin)), unique(select(dat, :dest)) ) # Load second dataset dat_airports = fread( \u0026#34;https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv\u0026#34;) # Inner join (default) merge(dat, dat_airports, by.x = c(\u0026#34;dest\u0026#34;), by.y = c(\u0026#34;faa\u0026#34;)) # if the datasets share a common name for the merge variable setnames(dat_airports, c(\u0026#34;faa\u0026#34;), c(\u0026#34;dest\u0026#34;)) merge(dat, dat_airports, by = c(\u0026#34;dest\u0026#34;)) # with missing values merge(dat, dat_airports, by = c(\u0026#34;dest\u0026#34;)) # Other types of merge # Left join merge(dat, dat_airports, by = c(\u0026#34;dest\u0026#34;), all.x = TRUE) # Right join merge(dat, dat_airports, by = c(\u0026#34;dest\u0026#34;), all.y = TRUE) # Outer join merge(dat, dat_airports, by = c(\u0026#34;dest\u0026#34;), all.x = TRUE, all.y = TRUE) # Semi join (filtering) merge(dat, dat_airports[, .(dest)], by = c(\u0026#34;dest\u0026#34;)) # Anti join dat[fsetdiff(dat[, .(dest)], dat_airports[, .(dest)]), on = \u0026#34;dest\u0026#34;] # Cross join CJ(unique(dat[[\u0026#34;origin\u0026#34;]]), unique(dat[[\u0026#34;dest\u0026#34;]])) # all combination of origin and destinations Advanced merging # Non-equi joins # dat3 = data.table(carrier = c(\u0026#39;AA\u0026#39;, \u0026#39;UA\u0026#39;), start_month = c(1, 4), end_month = c(3, 6)) # Rolling join that catches everything between the distinct # start and end dates for each carrier. dat[dat3, on = .(carrier, month \u0026gt;= start_month, month \u0026lt;= end_month)] Rolling joins # # Could not find it yet # Make sure we have a date variable dat[, date := as.IDate(paste(year, month, day, sep=\u0026#39;-\u0026#39;))] # New DT with the (random) target dates dat4 = data.table(carrier = c(\u0026#39;AA\u0026#39;, \u0026#39;UA\u0026#39;), new_date = as.IDate(c(\u0026#39;2014-11-01\u0026#39;, \u0026#39;2014-11-15\u0026#39;))) # Join on these target dates, so they take the last known value dat[dat4, on = .(carrier, date=new_date), roll=\u0026#39;nearest\u0026#39;] Appending data # vcat(dat, dat) vcat(dat, dat, cols=:union) reduce(vcat, [dat, dat]) reduce(vcat, [dat, dat], cols=:union) rbind(dat, dat) rbind(dat, dat, fill = TRUE) rbindlist(list(dat, dat)) # useful if working with list (purrr) rbindlist(list(dat, dat), fill = TRUE) "},{"id":3,"href":"/www/blog/posts/2021-10-Kleibergen-Paap/","title":"Kleibergen-Paap F-statistics in stata and julia","section":"Blog","content":"This was a joint effort with Matthieu Gomez who created and maintain the high-dimensional fixed effect regression package for julia FixedEffectModels.jl. Valentin Haddad and myself uncovered this bug while working on our project on passive investing and market competition.\nThis post describes how the Kleibergen-Paap first-stage F-statistics can be misleading when using ivreg2 and ivreghdfe in stata.\nIn julia the FixedEffectModels package deals with this type of regressions and usually mimicks stata. We found the issue was due to a specific case in the Kleibergen-Paap original paper and were able to patch it here. We find that the issue appears with instruments interacted with fixed effects.\ntl;dr; We found potential mistakes in stata\u0026rsquo;s ivreg2 and ivreghdfe for special cases. We found a way to fix it in julia\u0026rsquo;s FixedEffectModels; stata developers should look into patching it.\nFramework # We consider a model with two groups indexed by \\(k \\in {1,2}\\). We are interested in the following regression: $$ \\begin{align} Y_{i,k} \u0026amp;= \\alpha_k + \\beta_1 X_{i,1} + \\beta_2 X_{i,2} + \\varepsilon_i \\\\ X_{i,k} \u0026amp;= \\delta_k + \\gamma_k Z_{i,k} + u_{i,k} \\end{align} $$ The \\(X\\)s are endogenous regressors and the \\(Z\\)s are instruments. We are interested in a two-stage-least-squares regression of \\(Y\\) on \\(X\\) using the exogenous variation of the \\(Z\\).\nSetting up the problem # We set up the problem in julia (v1.6.0) and provide a minimal reproducible example. We start by setting up the packages and creating a small dataset (20 rows) with two identifiers.\nFirst we import the packages (sorry no checkpointing here apart from for the core package).\nIf you want to run this in isolation you can create a new directory and run it from there with julia --project=. and then activate the directory using Pkg; Pkg.activate(\u0026quot;.\u0026quot;); Pkg.instantiate()\nimport Pkg; Pkg.add(name=\u0026#34;FixedEffectModels\u0026#34;, version=\u0026#34;1.4.2\u0026#34;); # this new version has the fix Pkg.add(name=\u0026#34;Vcov\u0026#34;, version=\u0026#34;0.4.2\u0026#34;); # this new version has the fix # if you want to run the version without the fix (mimicks stata) # Pkg.add(name=\u0026#34;Vcov\u0026#34;, version=\u0026#34;1.4.0\u0026#34;); # Pkg.add(name=\u0026#34;Vcov\u0026#34;, version=\u0026#34;0.4.0\u0026#34;); # if you want to run the version without the fix (mimicks stata) Pkg.add([\u0026#34;Revise\u0026#34;, \u0026#34;CategoricalArrays\u0026#34;, \u0026#34;DataFrames\u0026#34;, \u0026#34;Random\u0026#34;, \u0026#34;CSV\u0026#34;, \u0026#34;Suppressor\u0026#34;]); Pkg.add([\u0026#34;Plots\u0026#34;, \u0026#34;PGFPlotsX\u0026#34;, \u0026#34;LaTeXStrings\u0026#34;]); Pkg.add([\u0026#34;FixedEffectModels\u0026#34;, \u0026#34;RegressionTables\u0026#34;]); Pkg.add(\u0026#34;RCall\u0026#34;); Pkg.add(url=\u0026#34;https://github.com/jmboehm/StataCall.jl#master\u0026#34;); And then load them for our session\nusing Printf using Revise, Suppressor using CategoricalArrays, DataFrames, CSV, Random using Plots, LaTeXStrings; pgfplotsx(size=(600, 400)); using FixedEffectModels using StataCall, RegressionTables using RCall Generating the dataset # The following function generates the dataset. We introduce a small \\(\\epsilon \\) to add noise to the instrument. This will be useful later as we show that the problem fails locally but not once we perturb the data.\nfunction gen_df(ϵ; seed::Int=107, N_rows=10) Random.seed!(seed) N_id = 2; i = 1 df_example = DataFrame() for i in 1:N_id obs = 1:N_rows id = i .* Int.(ones(N_rows)) Z = rand(N_rows) X = Z + 0.5 .* rand(N_rows) Y = 3 .* Z + 0.3 .* rand(N_rows) df_tmp = DataFrame(obs=obs, id = id, Z = Z, X = X, Y = Y) df_example = vcat(df_example, df_tmp) end df_example1 = unstack(select(df_example, :obs, :id, :X), [:obs, :id, :X], :id, :X, renamecols=x-\u0026gt;Symbol(:X, Int(x))) df_example2 = unstack(select(df_example, :obs, :id, :Z), [:obs, :id, :Z], :id, :Z, renamecols=x-\u0026gt;Symbol(:Z, Int(x))) df_example = innerjoin(df_example, select(df_example1, :obs, :id, :X1, :X2), on = [:obs, :id]) df_example = innerjoin(df_example, select(df_example2, :obs, :id, :Z1, :Z2), on = [:obs, :id]) df_example[ ismissing.(df_example.X1), :X1] .= 0.0; df_example[ ismissing.(df_example.X2), :X2] .= 0.0; df_example[ ismissing.(df_example.Z1), :Z1] .= 0.0; df_example[ ismissing.(df_example.Z2), :Z2] .= 0.0; transform!(df_example, :id =\u0026gt; categorical =\u0026gt; :id) transform!(df_example, :Z1 =\u0026gt; (x-\u0026gt; x .+ ϵ .* rand(N_id*N_rows)) =\u0026gt; :Z1eps) transform!(df_example, :Z2 =\u0026gt; (x-\u0026gt; x .+ ϵ .* rand(N_id*N_rows)) =\u0026gt; :Z2eps) return(df_example) end; And you can generate and view the data as follows:\n$ df_example = gen_df(0.01, seed=107, N_rows=10); $ show(df_example, display_size=(19, 200)) 20×11 DataFrame Row │ obs id Z X Y X1 X2 Z1 Z2 Z1eps Z2eps │ Int64 Cat… Float64 Float64 Float64 Float64? Float64? Float64? Float64? Float64 Float64 ─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────── 1 │ 1 1 0.119228 0.478444 0.587155 0.478444 0.0 0.119228 0.0 0.121428 3.31773e-5 2 │ 2 1 0.26591 0.568968 0.938078 0.568968 0.0 0.26591 0.0 0.272448 0.000209308 3 │ 3 1 0.745445 1.01965 2.25625 1.01965 0.0 0.745445 0.0 0.749129 0.00955548 4 │ 4 1 0.174331 0.208681 0.746424 0.208681 0.0 0.174331 0.0 0.178839 0.00739797 5 │ 5 1 0.370533 0.759199 1.20848 0.759199 0.0 0.370533 0.0 0.375502 0.00863599 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ 16 │ 6 2 0.674156 0.891977 2.10047 0.0 0.891977 0.0 0.674156 0.00662125 0.676856 17 │ 7 2 0.568036 0.787749 1.9021 0.0 0.787749 0.0 0.568036 0.00465503 0.57743 18 │ 8 2 0.935972 1.03212 3.03463 0.0 1.03212 0.0 0.935972 0.00264424 0.939824 19 │ 9 2 0.719989 0.927739 2.37524 0.0 0.927739 0.0 0.719989 0.00676318 0.729181 20 │ 10 2 0.840836 0.973702 2.75698 0.0 0.973702 0.0 0.840836 0.00371209 0.849899 10 rows omitted Running the regression: julia # We run two sets of regressions. These ones have the bug fix and should run correctly.\nThe first regression is the one described above. The second one uses the noisy instruments rather than the original instruments. The noisy instruments are defined as $$ Z_{i,k}^{\\epsilon} = Z_{i,k} + \\epsilon \\cdot \\text{Uniform} $$ What is interesting is how the Kleibergen-Paap statistics stay close as we perturb the data slightly.\nr1 = reg(df_example, @formula(Y ~ fe(id) + (X1 + X2 ~ Z1 + Z2) ), Vcov.robust() ); r2 = reg(df_example, @formula(Y ~ fe(id) + (X1 + X2 ~ Z1eps + Z2eps) ), Vcov.robust() ); And to view the results\n$ regtable(r1,r2; regression_statistics = [:f_kp]) --------------------------------------------- Y ------------------- (1) (2) --------------------------------------------- X1 3.415*** 3.395*** (0.771) (0.763) X2 4.129*** 4.135*** (0.474) (0.475) --------------------------------------------- id Fixed Effects Yes Yes --------------------------------------------- First-stage F statistic 12.231 12.432 --------------------------------------------- To check the smoothness of the statistic and that the knife-edge case has actually been fixed, we look at how the F-stat varies for different values of the perturbation.\nϵ_vec = range(-0.025, 0.025, length=25) F_vec = similar(ϵ_vec) iter_ϵ = 1 for iter_ϵ in 1:length(ϵ_vec) df_example = gen_df(ϵ_vec[iter_ϵ], seed=107, N_rows=10) r_tmp = reg(df_example, @formula(Y ~ fe(id) + (X1 + X2 ~ Z1eps + Z2eps) ), Vcov.robust() ) F_vec[iter_ϵ] = r_tmp.F_kp end plot(ϵ_vec, F_vec, xlabel=L\u0026#34;$\\epsilon$ Perturbation of Instrument Z\u0026#34;, ylabel=\u0026#34;Kleibergen-Paap first stage F-stat\u0026#34;, legend=false, dpi=300); plot!([0.0], seriestype=\u0026#34;vline\u0026#34;, color=:black) Running the regression: Stata # We use the StataCall package to run commands in stata. To set it up you need to make sure that julia has access to your path, see the repo for more details on how to do it for your system.\nIt might be easier to save the file and then load directly in stata.\ndf_example = gen_df(0.01, seed=107, N_rows=10); CSV.write(\u0026#34;./stata_data.csv\u0026#34;, df_example); If you go the StataCall route, you will simply pass the regression commands as strings:\ndfOut = StataCall.stataCall( [\u0026#34;ivreg2 Y (X1 X2 = Z1 Z2) id, robust\u0026#34;; \u0026#34;gen F = e(rkf)\u0026#34;; \u0026#34;ivreg2 Y (X1 X2 = Z1eps Z2eps) id, robust\u0026#34;; \u0026#34;gen Feps = e(rkf)\u0026#34;; ], df_example, true, true, true); # replace the last argument by false to see the stata-log Float64(dfOut.F[1]), Float64(dfOut.Feps[1]); # returns the F-stats We can confirm that the results are not smooth\n$ msg = \u0026#34;\\nF-statistics estimated with ivreg2 and exact instruments: F = \u0026#34; * @sprintf(\u0026#34;%.2f\u0026#34;, dfOut.F[1]) * \u0026#34;\\nF-statistics estimated with ivreg2 and ϵ-perturbed instruments: F = \u0026#34; * @sprintf(\u0026#34;%.2f\u0026#34;, dfOut.Feps[1]); $ @info msg ┌ Info: │ F-statistics estimated with ivreg2 and exact instruments: F = 0.00 └ F-statistics estimated with ivreg2 and ϵ-perturbed instruments: F = 12.43 We find that the result is 0 for the case with the actual instrument, which is not the expected result. We also checked whether the trick of perturbing the instruments might help and confirm the results above found in the julia code: the F-stat is 12.43 which corresponds to the desired estimate.\nWe try using ivreghdfe which suffers from similar issues. Note that ivreghdfe at least throws a warning (about collinearity) and does not return a number for the statistic. The peturbation still works well.\ndfOut = StataCall.stataCall( [\u0026#34;ivreghdfe Y (X1 X2 = Z1 Z2), absorb(id) robust\u0026#34;; \u0026#34;gen F = e(rkf)\u0026#34;; \u0026#34;ivreghdfe Y (X1 X2 = Z1eps Z2eps), absorb(id) robust\u0026#34;; \u0026#34;gen Feps = e(rkf)\u0026#34;; ], df_example, true, true, true); # replace the last argument by false to see the stata-log Fout = map(x-\u0026gt; ismissing(x) ? string(x) : @sprintf(\u0026#34;%.2f\u0026#34;, x), [dfOut.F[1], Float64(dfOut.Feps[1])] ) # returns the F-stats Same as before:\n$ msg = \u0026#34;\\nF-statistics estimated with ivreghdfe and exact instruments: F = \u0026#34; * Fout[1] * \u0026#34;\\nF-statistics estimated with ivreghdfe and ϵ-perturbed instruments: F = \u0026#34; * Fout[2] $ @info msg ┌ Info: │ F-statistics estimated with ivreghdfe and exact instruments: F = 0.00 └ F-statistics estimated with ivreghdfe and ϵ-perturbed instruments: F = 12.43 The fix to the covariance estimator only consisted of a few lines to handle a special case. You can see the commit here.\nIdeally this would be implemented in the stata code as well.\nRunning the regression: R # We use the RCall package to run commands in R within julia just as with StataCall (to run it make sure that your R environment is in the path, and of course install the relevant packages).\n# Load all relevant libraries to R (make sure they are installed in your R) @rput df_example @suppress begin R\u0026#34;\u0026#34;\u0026#34; library(data.table, verbose=T) library(lfe, verbose=T) library(fixest, verbose=T) library(texreg, verbose=T) dt_reg = data.table(df_example); dt_reg[, id := as.factor(id)]; \u0026#34;\u0026#34;\u0026#34; end RObject{VecSxp} It is hard to make sense of the results of felm here (note that I included id clustering, otherwise the estimation throws an error probably because of an zero inversion).\n# @suppress begin R\u0026#34;\u0026#34;\u0026#34; est_felm \u0026lt;- felm(Y ~ X1 + X2 | id | (X1 + X2 ~ Z1 + Z2) | id, dt_reg) est_felm_eps \u0026lt;- felm(Y ~ X1 + X2 | id | (X1 + X2 ~ Z1eps + Z2eps) | id, dt_reg) # res_s = screenreg(list(est_felm, est_felm_eps), include.fstatistic = T) \u0026#34;\u0026#34;\u0026#34; end @rget res_s print(res_s) The feols function detects collinearity in X1 and X2 which I do not understand, and stops there. Edit: this seems to gives us the correct results here.\n@suppress begin R\u0026#34;\u0026#34;\u0026#34; est_feols \u0026lt;- feols(Y ~ 1 | id | X1 + X2 ~ Z1 + Z2, dt_reg) est_feols_eps \u0026lt;- feols(Y ~ 1 | id | X1 + X2 ~ Z1eps + Z2eps, dt_reg) \u0026#34;\u0026#34;\u0026#34; # or run tests R\u0026#34;\u0026#34;\u0026#34; fitstat(est_feols, \u0026#34;ivf\u0026#34;) fitstat(est_feols_eps, \u0026#34;ivf\u0026#34;) fitstat(est_feols, \u0026#34;ivwald\u0026#34;) fitstat(est_feols_eps, \u0026#34;ivwald\u0026#34;) \u0026#34;\u0026#34;\u0026#34; end R\u0026#34;\u0026#34;\u0026#34; print(est_feols) print(est_feols_eps) \u0026#34;\u0026#34;\u0026#34; Perhaps we are missing other relevant packages that would take care of this issue (AER or estimatr). However these two are the fastest and most prevalent when dealing with relatively high-dimensional data. At this point it is not clear how to deal with this type of regressions in R.\n"},{"id":4,"href":"/www/blog/posts/2020-01-Tikz-Entry-Competition/","title":"Using TikZ and PGFPlots for Asset Pricing with Entry and Imperfect Competition","section":"Blog","content":"TikZ and PGFPlots in \u0026ldquo;Asset Pricing with Entry and Imperfect Competition\u0026rdquo;\nTo use the code just insert it into any LaTeX code with the appropriate tikz libraries; see here for examples.\nSummary of the economy # From blueprints, to production across two industries and aggregation of varieties into a final consumption bundle:\n\\tikzset{ pil/.style={ -\u0026gt;, thick, shorten \u0026lt;=0.1pt, shorten \u0026gt;=0.1pt,}, dasharrow/.style={ -\u0026gt;, thick, shorten \u0026lt;=1pt, shorten \u0026gt;=1pt, dashed}, } \\begin{tikzpicture}[scale=0.75] \\begin{scope}[color=black] \\draw (7,5) circle (1.5 cm); \\end{scope} \\node (const) at (7,5) { $\\mathbf{C_t}$ }; \\node[anchor=west, text width=3.5cm] (cons) at (14,5) { {Final consumption:\\\\ aggregation of industry goods}}; % differentiate industries \\node[text width=3cm](industry1) at (4,2.4) {}; \\node(industry2) at (10,2.4) {}; % consumption from industry east \\node (c1) at (8.5,5) {}; \\node (c2) at (10,2) {}; \\draw[pil, bend right=35, draw=blue ] (industry2.south) to (c1.east); \\node[anchor=west] (cons2) at (10,4) { $\\mathcal{C}_{2,t}$ }; % consumption from industry west \\node (c3) at (4,2) {}; \\node (c4) at (5.5,5) {}; \\draw[pil, bend left=35, draw=red ] (industry1.south) to (c4.west); \\node[anchor=east] (cons1) at (4,4) { $\\mathcal{C}_{1,t}$ }; \\begin{scope}[color=red] \\draw (4,0) circle (2cm); \\end{scope} \\begin{scope}[color=blue] \\draw (10,0cm) circle (2cm); \\end{scope} \\node[anchor=west, text width=3cm] (cons) at (14,0) { {Industry Level Product Market Competition}}; %firms in first industry circle \\node (11) at (5,1) {\\circle*{4}}; \\node (12) at (3,-0.1) {\\circle*{4}}; \\node (13) at (5.1,-0.8) {\\circle*{4}}; \\node (14) at (3.6,-1.1) {\\circle*{4}}; \\node (15) at (4,1.6) {\\circle*{4}}; \\node (16) at (4,0) {\\circle*{4}}; \\node (17) at (3.8,-0.8) {\\circle*{4}}; \\node (18) at (3.2,-1) {\\circle*{4}}; \\node (19) at (4.8,-1.1) {\\circle*{4}}; \\node (110) at (3,1) {\\circle*{4}}; \\node (111) at (5.2,0.1) {\\circle*{4}}; %firms in second industry circle \\node (21) at (11,1) {\\circle*{4}}; \\node (22) at (9,-1) {\\circle*{4}}; \\node (24) at (10,-.5) {\\circle*{4}}; \\node (25) at (11,0) {\\circle*{4}}; \\node[anchor=west] (omega11) at (0,1) {firm} ; \\draw[pil, bend left=30 ] (omega11.east) to (12.west); \\node[anchor=west] (omega12) at (0,-2.5) {industry} ; \\draw[pil, bend right=20 ] (omega12.east) to (3.5,-2cm); %innovators \\draw[thin] (2.5,-2.8)--(6,-2.8); \\draw[ultra thick] (8,-2.8)--(11.5,-2.8); \\node (31) at (4.8,-3.2) {\\circle{4}}; \\node (32) at (4.4,-3.5) {\\circle{4}}; \\node (33) at (5.2,-3.8) {\\circle{4}}; \\node (34) at (5.8,-3.4) {\\circle{4}}; \\node (35) at (4.6,-4.2) {\\circle{4}}; \\node (36) at (5.5,-4.2) {\\circle{4}}; \\node (37) at (10,-3.2) {\\circle{4}}; \\node (39) at (10.2,-3.8) {\\circle{4}}; \\node (310) at (9.8,-3.4) {\\circle{4}}; \\node (312) at (9.9,-4.1) {\\circle{4}}; \\node (313) at (9.1,-4) {\\circle{4}}; \\node (314) at (9.2,-3.2) {\\circle{4}}; \\node[anchor=west, text width=3cm,] (omega13) at (0,-4.8) {potential entrant \\\\(blueprint)} ; \\node (omega13b) at (3.3,-4.6) {} ; \\draw[pil, bend right=10 ] (omega13b.east) to (35.west); \\draw[dasharrow, bend right=30, draw=red ] (31.east) to (13.south); \\draw[dasharrow, bend left=30, draw=blue ] (310.west) to (22.south); \\node [anchor=west, text width=3.5cm, ] (innov) at (14,-3.5) {Innovation Sector}; \\end{tikzpicture} Industry Competition # Hotelling-Salop model of competition:\n\\newcommand{\\overbar}[1]{\\mkern 1.5mu\\overline{\\mkern-1.5mu#1\\mkern-1.5mu}\\mkern 1.5mu} \\begin{tikzpicture} \\begin{scope}[shift={(-7,0)}] \\foreach \\x [count=\\p] in {0,...,5} { \\node[shape=circle,fill=black, scale=0.5] (\\p) at (\\x*60:1) {}; \\node[shape=circle,fill=red, scale=0.5] (\\p) at (-30-\\x*60:1) {}; }; \\draw (1) arc (-30:360:1); \\draw [dotted, gray] (-1,0) -- (1,0); \\node[] (Mlo) at (0,0.2) {$\\overbar{M}_{lo}$}; \\end{scope} \\foreach \\x [count=\\p] in {0,...,5} { \\node[shape=circle,fill=black, scale=0.5] (\\p) at (\\x*60:3) {}; \\node[shape=circle,fill=red, scale=0.5] (\\p) at (-30-\\x*60:3) {}; }; \\draw (1) arc (-30:360:3); \\draw [dotted, gray] (-3,0) -- (3,0); \\node[] (Mhigh) at (0,0.2) {$\\overbar{M}_{hi}$}; \\end{tikzpicture} Entry Elasticity # \\begin{tikzpicture}[domain=0:5, scale=1, thick] \\tikzset{ % \u0026gt;=stealth\u0026#39; , pil/.style={ -\u0026gt;, thick, shorten \u0026lt;=0.1pt, shorten \u0026gt;=0.1pt,}, dasharrow/.style={ -\u0026gt;, thick, shorten \u0026lt;=1pt, shorten \u0026gt;=1pt, dashed}, %Define style for boxes } \\usetikzlibrary{calc} %allows coordinate calculations. \\tikzstyle{loosely dashed} = [dash pattern=on 6pt off 6pt] \\tikzstyle{dasharrow} = [-\u0026gt;, thick, shorten \u0026lt;=1pt, shorten \u0026gt;=1pt, dashed] % dot/.style={circle,fill=black,minimum size=4pt,inner sep=0pt, outer sep=-1pt}, %Define linear parameters for supply and demand \\def\\dint{4.5} %Y-intercept for DEMAND. \\def\\dslp{-0.5} %Slope for DEMAND. \\def\\sint{2} %Y-intercept for SUPPLY. \\def\\sslp{0.5} %Slope for SUPPLY. \\def\\demand{\\x,{\\dslp*\\x+\\dint}} \\def\\supply{\\x,{\\sslp*\\x+\\sint}} % Define coordinates. \\coordinate (ints) at ({(\\sint-\\dint)/(\\dslp-\\sslp)},{(\\sint-\\dint)/(\\dslp-\\sslp)*\\sslp+\\sint}); \\coordinate (ep) at (0,{(\\sint-\\dint)/(\\dslp-\\sslp)*\\sslp+\\sint}); \\coordinate (eq) at ({(\\sint-\\dint)/(\\dslp-\\sslp)},0); \\coordinate (dint) at (0,{\\dint}); \\coordinate (sint) at (0,{\\sint}); % DEMAND \\draw[thick,color=dark-gray, domain=0.25:5.25] plot (\\demand) node[right] {Demand}; % SUPPLY \\draw[very thick,color=black, domain=0.25:5.25] plot (\\supply) node[right] {Supply}; % supply going to infinity \\def\\fe{3.25} \\draw [loosely dashed, color=black] (0.2, \\fe) -- (5.5,\\fe); \\filldraw[fill=black, draw=black] (0,\\fe) circle (0.1); \\node[anchor=east] (fe) at (-0.1,\\fe) { $\\bar{v}_h$ }; \\node[anchor=south, color=dark-gray] (zeta) at (6,\\fe) { $\\zeta \\to \\infty$}; \\draw[-\u0026gt;, bend left=30, draw=dark-gray] (4.6,4.2) to (5.25,\\fe+0.1); % Draw axes, and dotted equilibrium lines. \\draw[-\u0026gt;] (0,0) -- (6.2,0) node[right] {\\Large{ $M_h$ }}; % axes \\draw[-\u0026gt;] (0,0) -- (0,6.2) node[above] {\\Large{ $v_h$ }}; \\end{tikzpicture} \\begin{tikzpicture}[domain=0:5, scale=1,thick] \\usetikzlibrary{calc} %allows coordinate calculations. \\tikzstyle{loosely dashed} = [dash pattern=on 6pt off 6pt] \\tikzstyle{dasharrow} = [-\u0026gt;, thick, shorten \u0026lt;=1pt, shorten \u0026gt;=1pt, dashed] %Define linear parameters for supply and demand \\def\\dint{4.5} %Y-intercept for DEMAND. \\def\\dslp{-0.5} %Slope for DEMAND. \\def\\sint{-2} %Y-intercept for SUPPLY. \\def\\sslp{2} %Slope for SUPPLY. \\def\\demand{\\x,{\\dslp*\\x+\\dint}} \\def\\supply{\\x,{\\sslp*\\x+\\sint}} % Define coordinates. \\coordinate (ints) at ({(\\sint-\\dint)/(\\dslp-\\sslp)},{(\\sint-\\dint)/(\\dslp-\\sslp)*\\sslp+\\sint}); \\coordinate (ep) at (0,{(\\sint-\\dint)/(\\dslp-\\sslp)*\\sslp+\\sint}); \\coordinate (eq) at ({(\\sint-\\dint)/(\\dslp-\\sslp)},0); \\coordinate (dint) at (0,{\\dint}); \\coordinate (sint) at (0,{\\sint}); % DEMAND \\draw[thick,color=dark-gray, domain=0.25:5] plot (\\demand) node[right] {Demand}; % SUPPLY \\draw[very thick,color=black, domain=1.25:4] plot (\\supply) node[right] {Supply}; \\def\\Me{2.6} \\draw [loosely dashed, color=black] (\\Me, 0) -- (\\Me, 6); \\filldraw[fill=black, draw=black] (\\Me, 0) circle (0.1); \\node[anchor=north] (me) at (\\Me, -0.1) { $\\bar{M}_h$ }; \\node[anchor=west, color=dark-gray] (zeta) at (\\Me, 0.5) { $\\zeta \\to 0$}; \\draw[-\u0026gt;, bend right=20, draw=dark-gray] (1.6,1) to (2.5,0.5); % Draw axes, and dotted equilibrium lines. \\draw[-\u0026gt;] (0,0) -- (6.2,0) node[right] {\\Large{ $M_h$ }}; % axes \\draw[-\u0026gt;] (0,0) -- (0,6.2) node[above] {\\Large{ $v_h$ }}; \\end{tikzpicture} "},{"id":5,"href":"/www/blog/posts/2021-07-Tikz-Bubbles/","title":"Using TikZ and PGFPlots for Bubbles and Innovation","section":"Blog","content":"TikZ and PGFPlots in \u0026ldquo;Bubbles and the Value of Innovation\u0026rdquo;\nTo use the code just insert it into any LaTeX code with the appropriate tikz libraries; see here for examples.\nHousehold disagreement # Households disagree on firms productivity and invest in them in consequence:\n\\tikzset{ pil/.style={ -\u0026gt;, thick, shorten \u0026lt;=0.5pt, shorten \u0026gt;=0.5pt,}, shaded/.style={circle,radius=\\r,draw, pattern=north west lines,pattern color=black}, households/.style={rectangle, draw, fill=black!10, inner sep=5pt, text width=4cm, text badly centered, minimum height=1.75cm, font=\\Large\\sffamily} } % ============================================= % Large circle split in 4 \\begin{scope}[color=black] \\draw[clip] (0, 0) circle (5cm); \\end{scope} \\draw [dashed] (0, 0) -- (0, 5); \\draw [dashed] (0, 0) -- (0, -5); \\draw [dashed] (0, 0) -- (5, 0); \\draw [dashed] (0, 0) -- (-5, 0); % ============================================= % Circles in each of the separation 1 \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc11) at (1.2, -3.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc12) at (2, -1.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc13) at (4, -2) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc13) at (1., -2) {}; % Circles in each of the separation 2 \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc31) at (-1.2, -3.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc32) at (-2, -1.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc33) at (-3.75, -2) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc13) at (-3., -3) {}; % Circles in each of the separation 3 \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc41) at (-1.2, 3.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc42) at (-2, 1.5) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc43) at (-3.75, 2) {}; \\node[circle, draw=black, fill=white, inner sep=0pt,minimum size=15pt] (dc13) at (-2.75, +2.75) {}; % Last circle for all the other groups \\node at (2, 2) {\\Huge \\emph{etc.}}; % ============================================= % Draw Households \\node (investor1) at (-8,-1) {}; \\node (investor2) at (-8, 1) {}; \\node[alice, shirt = blue, saturated, minimum size=1.cm] at (-8., -1.) {}; \\node[alice, shirt = red, skin=brown, hair=gray, saturated, minimum size=1.cm] at (-8., 1.) {}; \\node[alice, shirt = gray, skin=brown, saturated, minimum size=1.cm] at (-10., -1.) {}; \\node[bob, saturated, minimum size=1.cm] at (-10., 1.) {}; \\node[businessman, female, shirt = gray, skin=brown, minimum size=1.cm] at (-12., -1.) {}; \\node[charlie, shirt = gray, minimum size=1.cm] at (-12., 1.) {}; % ============================================= % Households Preferences \\node at (-0.7, -3.5) [red] {\\Large \\bfseries 3}; \\node at (-0.4, -3.5) [blue] {\\Large \\bfseries 1}; \\node at (-1.55, -1.5) [red] {\\Large \\bfseries 2}; \\node at (-1.25, -1.5) [blue] {\\Large \\bfseries 3}; \\node at (-3.3, -2) [red] {\\Large \\bfseries 1}; \\node at (-3., -2) [blue] {\\Large \\bfseries 2}; \\node at (-2.5, -3) [red] {\\Large \\bfseries 4}; \\node at (-2.2, -3) [blue] {\\Large \\bfseries 4}; % ============================================= % All rankings \\node at (-0.7, 3.5) [red] {\\Large \\bfseries 3}; \\node at (-0.4, 3.5) [blue] {\\Large \\bfseries 2}; \\node at (-1.55,1.5) [red] {\\Large \\bfseries 2}; \\node at (-1.25,1.5) [blue] {\\Large \\bfseries 1}; \\node at (-3.3, 2) [red] {\\Large \\bfseries 1}; \\node at (-3., 2) [blue] {\\Large \\bfseries 4}; \\node at (-2.3, 2.75) [red] {\\Large \\bfseries 4}; \\node at (-2.0, 2.75) [blue] {\\Large \\bfseries 3}; \\node at (1.65, -3.5) [red] {\\Large \\bfseries 1}; \\node at (1.95, -3.5) [blue] {\\Large \\bfseries 1}; \\node at (2.45,-1.5) [red] {\\Large \\bfseries 2}; \\node at (2.75,-1.5) [blue] {\\Large \\bfseries 3}; \\node at (3.3, -2) [red] {\\Large \\bfseries 3}; \\node at (3.55, -2) [blue] {\\Large \\bfseries 4}; \\node at (1.8, -2) [red] {\\Large \\bfseries 4}; \\node at (1.5, -2) [blue] {\\Large \\bfseries 2}; % ============================================= % Link Investors with their investments \\draw[pil, bend left=35, draw=red] (-7.5, 1) to (dc33.north); \\draw[pil, bend right=35, draw=blue] (-7.5, -1) to (dc31.west); \\draw[pil, bend left=35, draw=red] (-7.5, 1) to (dc43.west); \\draw[pil, bend right=35, draw=blue] (-7.5, -1) to (dc42.south); \\draw[pil, bend left=35, draw=red] (-7.5, 1) to (dc11.north); \\draw[pil, bend right=40, draw=blue] (-7.5, -1) to (dc11.south); \\node[circle, fill=blue, minimum size=15pt] (dc31blue) at (-1.2, -3.5) {}; \\node[circle, fill=red, minimum size=15pt] (dc33red) at (-3.75, -2) {}; \\node[circle, fill=blue, minimum size=15pt] (dc31blue) at (-2, 1.5) {}; \\node[circle, fill=red, minimum size=15pt] (dc33red) at (-3.75, 2) {}; \\node[semicircle, fill=blue, minimum size=7.5pt, rotate=90] (dc42blue) at (1.1, -3.5) {}; \\node[semicircle, fill=red, minimum size=7.5pt, rotate=270] at (1.3,-3.5) {}; Innovation Stage # Creation of blueprints and trading\n\\begin{scope}[color=black] \\node[households] (households) at (-7, -1) {Households $j$}; \\draw[myarrow] (0.2, 4.0) -- (-3.4, 0.25); \\node[households] (creators) at (13, -1) {Firm Creators}; \\node[align=left, font=\\footnotesize] (bs1) at (13, -3) {collects $p_i - p_b$}; \\draw[myarrow] (-3.4, -2.25) -- (0.2, -6); \\node[font = \\footnotesize, anchor = south] (firmprod) at (-3.9, -5) {Produce}; \\node[font = \\footnotesize, anchor = south] (firmprod) at (-3.9, -6.25) {effort cost $W(b)$}; \\draw[myarrow] (5.8, -6) -- (9.4, -2.25); \\node[font = \\footnotesize, anchor = south] (firmbuy) at (8.5, -5.5) {Buy}; \\draw[myarrow] (9.4 , 0.25) -- (5.8, 4.0); \\node[font = \\footnotesize, anchor = south] (firmbuy) at (8.5, 2) {Sell}; \\node[font = \\footnotesize, anchor = south] (firmprod) at (-3.7, 2) {Buy shares}; \\draw[dasharrow] (-3.5, -1) -- (9.5, -1); \\node[font = \\footnotesize, anchor = south] (firmbuy) at (3, -1) {Own}; % BLUEPRINTS \\draw (3,-7) circle (3cm); \\node[font=\\footnotesize, anchor=west] (blue) at (0.3,-6.) {\\textbf{Blueprints}}; \\node (bp11) at (2, -7.5) {\\circle{4}}; \\node (bp12) at (1.7, -8) {\\circle{4}}; \\node (bp13) at (2.4, -7.65) {\\circle{4}}; \\node (bp14) at (3, -9.2) {\\circle{4}}; \\node (bp15) at (1.9, -8.5) {\\circle{4}}; \\node (bp16) at (3, -9.7) {\\circle{4}}; \\node (bp17) at (3, -8) {\\circle{4}}; \\node (bp18) at (3.7, -7.2) {\\circle{4}}; \\node (bp19) at (4.4, -8.65) {\\circle{4}}; \\node (bp20) at (5, -9) {\\circle{4}}; \\node (bp21) at (3.9, -9.5) {\\circle{4}}; \\node (bp22) at (5, -7.7) {\\circle{4}}; % FIRMS \\draw (3, 5) circle (3cm); \\node[font=\\footnotesize] (consfirms) at ( 3, 6) {\\textbf{Firms} $i$}; \\draw (4.5, 4) circle (0.5cm); \\node at (4.5, 4) {?}; \\draw (3, 3.1) circle (0.5cm); \\node at (3, 3.1) {?}; \\draw (1.8, 3.3) circle (0.5cm); \\node at (1.8, 3.3) {?}; \\draw (2.6, 4.5) circle (0.5cm); \\node at (2.6, 4.5) {?}; \\end{scope} Production Stage # Firms compete and produce; consumers receive proceeds from their investments\n\\begin{scope}[color=black, xshift=0cm, yshift=0cm] \\node[households] (households) at (-7, -1) {Households $j$}; \\draw[myarrow] (0.2, 4.0) -- (-3.4, 0.25); \\node[font = \\footnotesize, anchor = south] (consbuy) at (-3.5, 2) {Consume}; \\draw[clip] (3, 5) circle (3cm); \\fill[gray!30] (0.5, 5) circle (3cm); \\node (dc15) at (2, 3.6) {\\circle*{8.2}}; \\node (dc11) at (1.5, 4.1) {\\circle*{8.2}}; \\node (dc14) at (2.8, 4) {\\circle*{9}}; \\node (dc12) at (2.8, 5.1) {\\circle*{8}}; \\node (dc13) at (2.1, 5.8) {\\circle*{10}}; \\node (dc16) at (2, 6.8) {\\circle*{11}}; \\draw [pattern=north west lines,pattern color=black] (4, 3) circle (2.25 mm); \\draw [pattern=north west lines,pattern color=black] (5.5, 4) circle (1.5 mm); \\draw [pattern=north west lines,pattern color=black] (4.7, 3.85) circle (1.9 mm); \\draw [pattern=north west lines,pattern color=black] (3.3, 6.75) circle (1.7 mm); \\draw [pattern=north west lines,pattern color=black] (4, 4) circle (1.2 mm); \\draw [pattern=north west lines,pattern color=black] (4, 5.5) circle (2 mm); \\draw [pattern=north west lines,pattern color=black] (5, 6) circle (1 mm); \\draw [pattern=north west lines,pattern color=black] (4.95, 6.7) circle (2.05 mm); \\node[font=\\footnotesize] (consfirms) at ( 3, 1.5) {\\textbf{Firms} $i$}; \\end{scope} "},{"id":6,"href":"/www/blog/posts/2020-01-Tikz-Investments/","title":"Using TikZ and PGFPlots for a class on Portfolio Investment","section":"Blog","content":"To use the code just insert it into any LaTeX code with the appropriate tikz libraries; see here for examples.\nOptimal Portfolio # Optimal portfolio allocation lies on the Capital Allocation Line (CAL) such that it maximizes the utility of the investor. Thus investor\u0026rsquo;s utility curve is tangent on that point to the CAL:\n\\begin{axis}[ height=7cm, width=12cm, axis x line=bottom, axis y line=left, xlabel = Standard Deviation, ylabel = Expected Return, ymin=0, ymax=25, xmin=0, xmax=60, extra x ticks={65}, extra x tick labels={$\\sigma$}, extra x tick style={major tick length=0mm, grid=none}, extra y ticks={25}, extra y tick labels={$\\mathbf{E}\\{R\\}$}, extra y tick style={major tick length=0mm, grid=none}, enlargelimits=true, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red} } ] \\addplot[color=black, domain=0:55, line width=1pt] {3 + x * 0.4}; % plot the capital allocation line \\addplot[color=red, domain=0:55, line width=1pt] {5 + 0.5 * (1/23) * x^2}; % plot the utility function \\addplot[scatter,only marks, scatter src=explicit symbolic] % plot the risk-free rate and the market and the allocation coordinates { (0,3) [a] (20, 11) [a] (10, 7) [b] }; \\node at (axis cs:0,3) [anchor=north west] {Riskfree, $R_f$}; \\node at (axis cs:20,11) [anchor=north west] {Risky, $R_s$}; \\node[rotate=27] at (axis cs:50, 23) [anchor=south east] {\\textbf{CAL}}; \\node[color=red] at (axis cs:27, 25) [anchor=south west] {\\textbf{U}}; \\node[pin={[pin edge={thick}, pin distance=2cm]90:{Optimal Porfolio}}] at (axis cs:10,7.5) {}; \\end{axis} Efficient Frontier # Case of two or more than two assets\nTwo Assets # \\begin{axis}[ height=7cm, width=12cm, axis x line=bottom, axis y line=left, xlabel = Standard Deviation, ylabel = Expected Return, ymin=0, ymax=25, xmin=0, xmax=60, extra x ticks={65}, extra x tick labels={$\\sigma$}, extra x tick style={major tick length=0mm, grid=none}, extra y ticks={25}, extra y tick labels={$\\mathbf{E}\\{R\\}$}, extra y tick style={major tick length=0mm, grid=none}, enlargelimits=true, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red} } ] \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (20, 11) [a] (12, 5) [a] }; \\node at (axis cs:12, 5) [anchor=north east] {Asset 1}; \\node at (axis cs:20,11) [anchor=north west] {Asset 2}; \\addplot[red, very thick, domain=-1:2.5, samples=200, variable=\\t]( {(20^2*t^2 + 12^2*(1-t)^2)^(0.5) }, %{(t^2 * 20^2 + (1-t)^2 * 12)}, {11 * t + (1-t) * 5} ); \\node[rotate=18, color=red] at (axis cs:50, 20) [anchor=south east] {\\textbf{Efficient Frontier}}; \\end{axis} More than two Assets # \\begin{axis}[ height=7cm, width=12cm, axis x line=bottom, axis y line=left, xlabel = Standard Deviation, ylabel = Expected Return, ymin=0, ymax=25, xmin=0, xmax=60, extra x ticks={65}, extra x tick labels={$\\sigma$}, extra x tick style={major tick length=0mm, grid=none}, extra y ticks={25}, extra y tick labels={$\\mathbf{E}\\{R\\}$}, extra y tick style={major tick length=0mm, grid=none}, enlargelimits=true, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red}, c={mark=*, mark size = 3pt,draw=black, fill = black} } ] \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (30, 11) [c] (19, 5) [c] (40, 15) [c] (16, 10) [b] }; \\node at (axis cs:19, 5) [anchor=north west] {MSFT}; \\node at (axis cs:30,11) [anchor=north west] {AAPL}; \\node at (axis cs:40,15) [anchor=north west] {KO}; \\addplot[red, very thick, domain=-1:2.5, samples=200, variable=\\t]( {(20^2*t^2 + 12^2*(1-t)^2)^(0.5) }, %{(t^2 * 20^2 + (1-t)^2 * 12)}, {11 * t + (1-t) * 5} ); \\node[color=red] at (axis cs:30, 0) [anchor=south west] {\\textbf{Efficient Frontier}}; \\addplot[black, very thick, domain=-10:50, samples=100, variable=\\x]( ({x}, {4 + 0.37 * x}); \\node[rotate = 25, color=black] at (axis cs:30, 15) [anchor=south west] {\\textbf{Optimal CAL}}; \\node[pin={[pin edge={thick}, text width=3cm, pin distance=2cm]90:{{\\centering Mean Variance Efficient Porfolio}}}] at (axis cs:16, 10.5) {}; \\end{axis} Security Market Line # \\begin{axis}[ height=7cm, width=12cm, axis x line=bottom, axis y line=left, xlabel = Market Risk, ylabel = Expected Return, ymin=0, ymax=24, xmin=0, xmax=2.5, xtick={0, 0.5, 1, 1.5, 2}, extra x ticks={2.5}, extra x tick labels={$\\beta$}, extra x tick style={ major tick length=0mm, grid=none }, ytick={3, 7, 11, 15}, yticklabels={$R_f$, $R_1$, $R_M$, $R_2$}, extra y ticks={23}, extra y tick labels={$\\mathbf{E}\\{R\\}$}, extra y tick style={ major tick length=0mm, grid=none }, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red}, c={mark=*, mark size = 3pt,draw=black, fill = black} } ] \\addplot[color=black, domain=-10:3, line width=1pt] {3 + x * 8}; \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (0,3) [a] (1, 11) [b] (0.5, 7) [c] (1.5, 15) [c] }; \\draw[dashed] (axis cs:0.5,0) -- (axis cs:0.5,7); \\draw[dashed] (axis cs:1.5,0) -- (axis cs:1.5,15); \\draw[dashed, color=red] (axis cs:1,0) -- (axis cs:1,11); \\draw[dotted] (axis cs:0,7) -- (axis cs:0.5,7); \\draw[dotted] (axis cs:0,15) -- (axis cs:1.5,15); \\draw[dotted, color=red] (axis cs:0,11) -- (axis cs:1,11); \\node[rotate=23] at (axis cs:2.4, 23) [anchor=south east] {\\textbf{Security Market Line}}; \\node[pin={[pin edge={thick}, pin distance=2cm]90:{Market Porfolio}}] at (axis cs:1,11.5) {}; \\end{axis} Capital Market Line and Security Market Line # \\begin{tikzpicture} \\begin{groupplot}[ group style={group size=2 by 1, horizontal sep=2cm}, no markers, height=7cm, width=10cm, axis x line=bottom, axis y line=left, ymin=0, ymax=24, extra y ticks={23}, extra y tick labels={$\\mathbf{E}\\{R\\}$}, extra y tick style={major tick length=0mm, grid=none}, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red}, c={mark=*, mark size = 3pt,draw=black, fill = black} } ] % PLOT 1 \\nextgroupplot[ xlabel = Standard Deviation, ylabel = Expected Return, xmin=0, xmax=55, extra x ticks={55}, extra x tick labels={$\\sigma$}, extra x tick style={major tick length=0mm, grid=none}, xtick={0, 16, 30, 40 }, xticklabels={0, $\\sigma_M$, $\\sigma_{\\text{AAPL}}$, $\\sigma_{\\text{KO}}$ }, ytick={3, 5, 10, 15}, yticklabels={$R_f$, $R_{\\text{MSFT}}$, $R_M$, $R_{\\text{KO}}$} ] \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (30, 11) [c] (19, 5) [c] (40, 15) [c] (16, 10) [b] }; \\node at (axis cs:19, 5) [anchor=north west] {MSFT}; \\node at (axis cs:30,11) [anchor=south west] {AAPL}; \\node at (axis cs:40,15) [anchor=north west] {KO}; \\addplot[red, very thick, domain=-0.5:2.5, samples=200, variable=\\t]( {(18^2*t^2 + 16^2*(1-t)^2)^(0.5) }, %{(t^2 * 20^2 + (1-t)^2 * 12)}, {11 * t + (1-t) * 4} ); \\addplot[black, very thick, domain=-10:50, samples=100, variable=\\x](({x}, {3 + 7/16 * x}); \\node[rotate = 35, color=black] at (axis cs:30, 16) [anchor=south west]{\\textbf{Optimal CAL}}; \\node[pin={[pin edge={thick}, text width=3cm, pin distance=2cm]90:{{\\centering Mean Variance Efficient Porfolio}}}] at (axis cs:16, 10.5) {}; \\draw[dotted, color=red] (axis cs:0, 10) -- (axis cs: 16,10); \\draw[dashed, thick, color=red] (axis cs:16, 10) -- (axis cs: 55,10); \\node[] (market1) at (axis cs:55.,10) {}; \\draw[dotted] (axis cs:0, 15) -- (axis cs: 40, 15); \\draw[dashed] (axis cs:40, 15) -- (axis cs: 55,15); \\node[] (ko1) at (axis cs:55.,15) {}; \\draw[dotted] (axis cs:0, 5) -- (axis cs: 19, 5); \\draw[dashed] (axis cs:19, 5) -- (axis cs: 55,5); \\node[] (ms1) at (axis cs:55, 5) {}; % PLOT 2 \\nextgroupplot[ xlabel = Market Risk, xmin=0, xmax=2, xtick={0, 1, 0.2857142857142857, 1.7142857142857142}, xticklabels={0 , $\\beta^M$, $\\beta^{\\text{MSFT}}$, $\\beta^{\\text{KO}}$}, ytick=\\empty ] \\addplot[color=black, domain=-10:3, line width=1pt]{3 + x * 7}; \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (0,3) [a] (1, 10) [b] (2/7, 5) [c] (12/7, 15) [c] }; \\draw[dotted, color=red] (axis cs:1,0) -- (axis cs:1,10); \\draw[dashed, color=red] (axis cs:0,10) -- (axis cs:1,10); \\draw[dotted] (axis cs:12/7,0) -- (axis cs:12/7, 15); \\draw[dashed] (axis cs:0,15) -- (axis cs:12/7,15); \\draw[dotted] (axis cs:2/7,0) -- (axis cs:2/7, 5); \\draw[dashed] (axis cs:0,5) -- (axis cs:2/7,5); \\node[] (market2) at (axis cs:0.,10) {}; \\node[] (ko2) at (axis cs:0,15) {}; \\node[] (ms2) at (axis cs:0, 5) {}; \\node[rotate=23] at (axis cs:2.4, 23) [anchor=south east] {\\textbf{SML}}; \\node[pin={[pin edge={thick}, pin distance=2cm]90:{Market Porfolio}}] at (axis cs:1,11.5) {}; \\end{groupplot} \\draw[dashed, thick, red] (market1) -- (market2) ; \\draw[dashed] (ko1) -- (ko2) ; \\draw[dashed] (ms1) -- (ms2) ; \\end{tikzpicture} Treynor-Black Portfolio Selection # If investors have information on some portfolio, they might want to trade beyond the passive allocation of holding the market portfolio. How much should they weigh the \u0026ldquo;active\u0026rdquo; section of their portfolio with respect to their passive investment? Standard mean-variance algebra gives a formula for the maximum Sharpe ratio of a portfolio of two risky assets. Coupled with the \u0026ldquo;diagonal version\u0026rdquo; of the market model, we find that the weight corresponds to the ratio of excess returns to variances.\n\\begin{axis}[ height=7cm, width=12cm, axis x line=bottom, axis y line=left, xlabel = Standard Deviation, ylabel = Expected Return, ymin=0, ymax=35, xmin=0, xmax=35, xtick={0, 10, 20, 30}, extra x ticks={35}, extra x tick labels={$\\sigma$}, extra x tick style={major tick length=0mm, grid=none}, extra y ticks={3, 35}, extra y tick labels={$r_f$, $\\mathbf{E}\\{R\\}$}, extra y tick style={major tick length=0mm, grid=none}, enlargelimits=false, scatter/classes={ a={mark=o,draw=black, mark size = 3pt}, b={mark=*, mark size = 3pt,draw=red, fill = red}, c={mark=*, mark size = 3pt,draw=black, fill = black} } ] \\pgfmathsetmacro{\\rf}{2} \\pgfmathsetmacro{\\muM}{8} \\pgfmathsetmacro{\\sigM}{9} \\pgfmathsetmacro{\\muA}{20} \\pgfmathsetmacro{\\sigA}{15} \\pgfmathsetmacro{\\rhoAM}{0.1} \\pgfmathsetmacro{\\sigAM}{\\sigA * \\sigM * \\rhoAM} \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (\\sigM, \\muM+\\rf) [c] (\\sigA, \\muA+\\rf) [c] }; \\node at (axis cs:\\sigM, \\muM+\\rf) [anchor=south west] {Market Portfolio}; \\node at (axis cs:\\sigA, \\muA+\\rf) [anchor=north west] {Active Portfolio}; \\pgfmathsetmacro{\\omA}{(\\muM*\\sigAM - \\muA * \\sigM^2) / ( (\\muA+\\muM)*\\sigAM - \\muA*\\sigM^2 - \\muM*\\sigA^2)} \\pgfmathsetmacro{\\muP}{\\omA * \\muA + (1-\\omA) * \\muM} \\pgfmathsetmacro{\\sigP}{(\\omA^2 * \\sigA^2 + (1-\\omA)^2 * \\sigM^2 + 2*\\omA*(1-\\omA)*\\sigAM)^(1/2)} \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (\\sigP, \\muP+2) [b] }; \\addplot[red, very thick, domain=-0.75:1.5, samples=200, variable=\\t]( {(\\sigA^2 * t^2 + \\sigM^2*(1-t)^2 + 2*t*(1-t)*\\sigAM)^(0.5)}, {\\muA * t + (1-t) * \\muM + \\rf} ); \\addplot[black, very thick, domain=0:18, samples=100, variable=\\x]( ({x}, {2 + \\muP/\\sigP * x}); \\node[pin={[pin edge={thick}, text width=3cm, pin distance=1.5cm]90:{{\\centering maximum Sharpe Ratio portfolio}}}] at (axis cs:\\sigP, \\muP+3) {}; \\node[text centered, text width = 5cm] at (axis cs:20, 10) [anchor=south west] {{Active portfolio weight: \\\\$\\omega_a = \\frac{\\alpha_A/\\sigma_A^2}{\\mu_M / \\sigma_M^2}$}}; \\end{axis} "},{"id":7,"href":"/www/blog/posts/2020-05-Tikz-MWE/","title":"Integrating TikZ Pictures in a LaTeX environment","section":"Blog","content":"I provide some examples of complete LaTeX code to produce documents that include TikZ figures\nMinimal Working Example # A simple document with the minimal class: view output from pdflatex here\n\\documentclass{standalone} % -------------------------------------------------------- \\usepackage{amsmath} \\usepackage{textcomp} \\usepackage{tikz} \\usepackage{pgfplots} % -------------------------------------------------------- \\usetikzlibrary{shapes, arrows} \\usetikzlibrary{positioning} \\usetikzlibrary{matrix} \\usetikzlibrary{plotmarks} \\usetikzlibrary{arrows.meta} \\usepgfplotslibrary{groupplots} \\pgfplotsset{compat=newest} % -------------------------------------------------------- \\begin{document} % Definition of blocks: \\tikzset{% block/.style = {draw, thick, rectangle, minimum height = 3em, minimum width = 3em}, sum/.style = {draw, circle, node distance = 2cm}, % Adder input/.style = {coordinate}, % Input output/.style = {coordinate}, % Output \u0026gt;={Latex[width=2mm,length=2mm]}, % Specifications for style of nodes: base/.style = {rectangle, rounded corners, draw=black, minimum width=4cm, minimum height=1cm, text centered, font=\\sffamily}, activityStarts/.style = {base, fill=blue!30}, startstop/.style = {base, fill=red!30}, activityRuns/.style = {base, fill=green!30}, process/.style = {base, minimum width=2.5cm, fill=orange!15, font=\\ttfamily} } \\begin{tikzpicture}[ node distance=2cm, every node/.style={fill=white, font=\\sffamily}, align=center ] % Specification of nodes (position, etc.) \\node (start) [activityStarts] {US Investor at $t=0$}; \\node (borrowing0) [process, above=2.5cm of start] {US Bank}; \\node (exchange0) [process, below=2.5cm of start] {Exchange Counterparty}; \\node (lending01) [process, right=3.5cm of start] {Japanese Investor}; \\node (end) [activityStarts, right=3.5cm of lending01] {US Investor at $t=1$}; \\node (borrowing1) [process, above=2.5cm of end] {US Bank}; \\node (exchange1) [process, below=2.5cm of end] {Exchange Counterparty}; % Link the nodes \\draw[-\u0026gt;](borrowing0) -- node[]{Borrowing in USD} (start); \\draw[-\u0026gt;](start) -- node[]{Buy Yen at rate $x_0$\\\\ buy for $\\$1$ receive $\\text{\\textyen}\\ 1 / x_0$}(exchange0); \\draw[-\u0026gt;](start) -- node[text width = 2.4cm]{Lend $1/x_0$ Yens at $t=0$} (lending01); \\draw[-\u0026gt;](lending01) -- node[text width = 2.4cm]{Receive Yens: $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}})$} (end); \\draw[-\u0026gt;](end) -- node[]{Repay USD loan at $t=1$ for \\\\$1+r$} (borrowing1); \\draw[-\u0026gt;](exchange1) -- node[]{Exchange the \\textyen \\ investment in USD\\\\ $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}}) \\cdot F_{0,1}$} (end); \\end{tikzpicture} \\end{document} Standard Article Class # A document with the article class: view output from pdflatex here\n\\documentclass{article} % -------------------------------------------------------- \\usepackage{amsmath} \\usepackage{textcomp} \\usepackage{pdflscape} \\usepackage{tikz} \\usepackage{pgfplots} % -------------------------------------------------------- \\usetikzlibrary{shapes, arrows} \\usetikzlibrary{positioning} \\usetikzlibrary{matrix} \\usetikzlibrary{plotmarks} \\usetikzlibrary{arrows.meta} \\usepgfplotslibrary{groupplots} \\pgfplotsset{compat=newest} % -------------------------------------------------------- \\begin{document} % Definition of blocks: \\tikzset{% block/.style = {draw, thick, rectangle, minimum height = 3em, minimum width = 3em}, sum/.style = {draw, circle, node distance = 2cm}, % Adder input/.style = {coordinate}, % Input output/.style = {coordinate}, % Output \u0026gt;={Latex[width=2mm,length=2mm]}, % Specifications for style of nodes: base/.style = {rectangle, rounded corners, draw=black, minimum width=4cm, minimum height=1cm, text centered, font=\\sffamily}, activityStarts/.style = {base, fill=blue!30}, startstop/.style = {base, fill=red!30}, activityRuns/.style = {base, fill=green!30}, process/.style = {base, minimum width=2.5cm, fill=orange!15, font=\\ttfamily} } \\begin{landscape} \\begin{figure} \\begin{tikzpicture}[ node distance=2cm, every node/.style={fill=white, font=\\sffamily}, align=center ] % Specification of nodes (position, etc.) \\node (start) [activityStarts] {US Investor at $t=0$}; \\node (borrowing0) [process, above=2.5cm of start] {US Bank}; \\node (exchange0) [process, below=2.5cm of start] {Exchange Counterparty}; \\node (lending01) [process, right=3.5cm of start] {Japanese Investor}; \\node (end) [activityStarts, right=3.5cm of lending01] {US Investor at $t=1$}; \\node (borrowing1) [process, above=2.5cm of end] {US Bank}; \\node (exchange1) [process, below=2.5cm of end] {Exchange Counterparty}; % Link the nodes \\draw[-\u0026gt;](borrowing0) -- node[]{Borrowing in USD} (start); \\draw[-\u0026gt;](start) -- node[]{Buy Yen at rate $x_0$\\\\ buy for $\\$1$ receive $\\text{\\textyen}\\ 1 / x_0$}(exchange0); \\draw[-\u0026gt;](start) -- node[text width = 2.4cm]{Lend $1/x_0$ Yens at $t=0$} (lending01); \\draw[-\u0026gt;](lending01) -- node[text width = 2.4cm]{Receive Yens: $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}})$} (end); \\draw[-\u0026gt;](end) -- node[]{Repay USD loan at $t=1$ for \\\\$1+r$} (borrowing1); \\draw[-\u0026gt;](exchange1) -- node[]{Exchange the \\textyen \\ investment in USD\\\\ $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}}) \\cdot F_{0,1}$} (end); \\end{tikzpicture} \\end{figure} \\end{landscape} \\end{document} "},{"id":8,"href":"/www/blog/posts/2020-05-Tikz-for-Discussions/","title":"Using TikZ and PGFPlots for paper discussions","section":"Blog","content":"To use the code just insert it into any LaTeX code with the appropriate tikz libraries; see herefor examples.\nProspect theory # Discussion of Prospect Theory and Stock Markets Anomalies (Barberis, Jin, and Wang)\n\\begin{tikzpicture} \\begin{groupplot}[ group style={group size=2 by 1, horizontal sep=2cm}, no markers, height=5cm, width=7cm, axis x line=bottom, axis y line=left ] % PLOT 1 \\nextgroupplot[ xlabel = Payoff, ylabel = $v(x)$, xmin=-2, xmax=2, ymin=-4, ymax=3, extra x tick style={major tick length=0mm, grid=none}, xtick={-2, 0, 2}, xticklabels={-2, 0, 2}, ytick={-4, 0, 3} ] \\addplot[red, thick, domain=-2:2, samples=200, variable=\\t]( {t }, { ((t+abs(t))/2)^(0.5) - 2.5 * ((abs(t)-t)/2)^0.5 } ); \\draw[dotted, color=black] (axis cs:-2,0) -- (axis cs:2,0); \\draw[dotted, color=black] (axis cs:0,-4) -- (axis cs:0,3); % PLOT 2 \\nextgroupplot[ xlabel = P, ylabel = $w(P)$, xmin=0, xmax=1, ymin=0, ymax=1, xtick={0, 0.5, 1}, ytick={0, 0.5, 1} ] \\addplot[color=black, dotted, domain=0:1, samples=100, variable=\\t ]( {t }, {t^1 / (t^1 + (1-t)^1)^(1/1) } ); \\addplot[color=black, dashed, domain=0:1, samples=100, variable=\\t]( {t }, {t^0.65 / (t^0.65 + (1-t)^0.65)^(1/0.65) } ); \\addplot[color=black, solid, domain=0:1, samples=100, variable=\\t]( {t }, {t^0.4 / (t^0.4 + (1-t)^0.4)^(1/0.4) } ); \\end{groupplot} \\end{tikzpicture} "},{"id":9,"href":"/www/blog/posts/2020-01-Tikz-Options/","title":"Using TikZ and PGFPlots for a class on Options and Derivatives","section":"Blog","content":"To use the code just insert it into any LaTeX code with the appropriate tikz libraries; see here for examples.\nPayoff of a Forward Contract # Payoff of a forward contract is linear in the underlying security:\n\\begin{tikzpicture} \\begin{axis}[ height=10cm, width=14cm, axis x line=bottom, axis y line=left, xlabel = Spot Price $S_T$, ylabel = Payoff, ymin=-32, ymax=32, xmin=70, xmax=132, xtick={80, 100, 120, 130}, ytick={-20, 0, 20, 30}, grid = major, grid style={dashed}, scatter/classes={ a={mark=*, mark size = 3pt,draw=black, fill = black} } ] \\definecolor{maroon}{RGB}{128, 0, 0} \\addplot[color=black, domain=70:130, line width=1pt] {x - 100}; \\addplot[color=maroon, dashed, domain=70:130, line width=1pt] {100 - x}; \\node[pin={[pin edge={thick}, text width=3cm, pin distance=2cm]-90:{{\\centering Forward Price $F_{0,T}$}}}, align=center] at (axis cs:100, -1) {}; \\addplot[scatter,only marks, scatter src=explicit symbolic] coordinates { (100,0) [a] }; \\node[text width=3cm,align=right] at (axis cs:120, 20) [anchor=south east] {\\textbf{Long Forward}\\\\$S_T - F_{0,T}$}; \\node[text width=3cm,align=left] at (axis cs:80, 20) [anchor=south west] {\\textbf{Short Forward}\\\\$F_{0,T} - S_T$}; \\end{axis} \\end{tikzpicture} Covered Interest Parity # Replicating foreign interest rate using exchange rate and a forward:\n% Definition of blocks: \\tikzset{% block/.style = {draw, thick, rectangle, minimum height = 3em, minimum width = 3em}, sum/.style = {draw, circle, node distance = 2cm}, % Adder input/.style = {coordinate}, % Input output/.style = {coordinate}, % Output \u0026gt;={Latex[width=2mm,length=2mm]}, % Specifications for style of nodes: base/.style = {rectangle, rounded corners, draw=black, minimum width=4cm, minimum height=1cm, text centered, font=\\sffamily}, activityStarts/.style = {base, fill=blue!30}, startstop/.style = {base, fill=red!30}, activityRuns/.style = {base, fill=green!30}, process/.style = {base, minimum width=2.5cm, fill=orange!15, font=\\ttfamily} } \\begin{tikzpicture}[ node distance=2cm, every node/.style={fill=white, font=\\sffamily}, align=center ] % Specification of nodes (position, etc.) \\node (start) [activityStarts] {US Investor at $t=0$}; \\node (borrowing0) [process, above=2.5cm of start] {US Bank}; \\node (exchange0) [process, below=2.5cm of start] {Exchange Counterparty}; \\node (lending01) [process, right=3.5cm of start] {Japanese Investor}; \\node (end) [activityStarts, right=3.5cm of lending01] {US Investor at $t=1$}; \\node (borrowing1) [process, above=2.5cm of end] {US Bank}; \\node (exchange1) [process, below=2.5cm of end] {Exchange Counterparty}; % Link the nodes \\draw[-\u0026gt;](borrowing0) -- node[]{Borrowing in USD} (start); \\draw[-\u0026gt;](start) -- node[]{Buy Yen at rate $x_0$\\\\ buy for $\\$1$ receive $\\text{\\textyen}\\ 1 / x_0$}(exchange0); \\draw[-\u0026gt;](start) -- node[text width = 2.4cm]{Lend $1/x_0$ Yens at $t=0$} (lending01); \\draw[-\u0026gt;](lending01) -- node[text width = 2.4cm]{Receive Yens: $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}})$} (end); \\draw[-\u0026gt;](end) -- node[]{Repay USD loan at $t=1$ for \\\\$1+r$} (borrowing1); \\draw[-\u0026gt;](exchange1) -- node[]{Exchange the \\textyen \\ investment in USD\\\\ $\\frac{1}{x_0} \\cdot (1+r^{\\text{\\textyen}}) \\cdot F_{0,1}$} (end); \\end{tikzpicture} "}]