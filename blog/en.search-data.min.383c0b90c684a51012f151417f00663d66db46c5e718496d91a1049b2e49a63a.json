[{"id":0,"href":"/www/blog/posts/2024-03-TAQ-Consolidated-Data/","title":"Processing TAQ Consolidated Data","section":"Blog","content":"For a recent revision, I have had to dig into TAQ data. This is something relatively new to me, but I had to figure out some statistics out of the consolidated trade data. I did not want to use SAS because I do not have a PC running windows, and SAS for linux is very painful. So here is a method for getting annoying statistics from annoyingly large data.\nThe goal was to estimate the order imbalance volatility on the U.S. stock market. Order imbalance is defined as the difference between volume bought and sold scaled by the total volume exchanged:1\nOIBNUM: the number of buyer-initiated trades less the number of seller-initiated trades on day t. OIBSH: the buyer-initiated shares purchased less the seller-initiated shares sold on day t. OIBDOL: the buyer-initiated dollars paid less the seller-initiated dollars received on day t. It is too onerous (memory) to process everything at once, the goal of this guide is to show how to parallelize the process of working with this data stock by stock.\nData # For this I worked with the Trade and Quote (TAQ) data. Specifically, I downloaded consolidated trades data which is available from 1993 to 2014 directly from WRDS.2\nI downloaded the data year by year which took a little while given the size of each individual year (a gzipped extract in 2008 is above 26Gb and expands to 300Gb). Once downloaded, I reuploaded all the data to a s3 bucket where I have easy access to it.\nThe data includes a symbol for the stock id (there is a match table to permno on WRDS), a price, and a size.\nPreprocessing # I will process one year of data at a time \u0026mdash; technically, the algorithm for estimating whether a trade is a buy or sell could suffer from this, but I think the error is minimal here.\nThe preprocessing happens using a standard shell (bash or zsh).\nDefining variables # It is important to define a few variables for the shell\nThe relevant year: DATEY=2006 The number of processors available: nprocs=128 The memory available mem_alloc=512 (for example if you have 512G of ram available) A directory with lots of space (~1Tb) where you can expand and work with the data: TAQ_HOME=\u0026quot;/big_space_disk/\u0026quot; Download and expand the data # First I download the data from the s3 bucket using s5cmd as:3\n$ input_file=\u0026#34;TAQ_name_$DATEY\u0026#34; $ s5cmd cp s3://my-bucket/TAQ/$input_file.csv.gz $TAQ_HOME/ Then I expand the data; I take advantage of multicore expansion using pigz.\nFirst I peak at the data to check that the data has the correct columns and that the year is correct:\n$ pigz -cd | head -n 5 SYMBOL,DATE,TIME,PRICE,SIZE,G127,CORR,COND,EX A,2006-01-03,8:00:07,33.29,30000,0,0,U,T A,2006-01-03,8:08:01,33.29,8300,0,0,T,T A,2006-01-03,8:17:28,33.29,8600,0,0,T,T A,2006-01-03,9:30:22,33.4,96200,40,0,,N Once I have confirmed that I am looking at the right thing I expand the whole file:\n$ pigz -dc $TAQ_HOME/$input_file.csv.gz \u0026gt; $TAQ_HOME/taq_select.csv.gz For efficiency (untested), I have actually use the binaries from xsv4 to select only the columns from the file that I needed. Simply replace the previous command with:\npigz -cd $TAQ_HOME/$input_file.csv.gz | \\ xsv select \u0026#34;SYMBOL,DATE,TIME,PRICE,SIZE\u0026#34; \u0026gt; $TAQ_HOME/taq_select.csv Note that this is fairly slow and can take upwards of 20 minutes even reading the file from the ram disk.\nSort the data # In theory the data coming out of WRDS are already sorted by \u0026ldquo;SYMBOL\u0026rdquo;. But the strategy relies heavily on this step being accurate and it is always a good thing to learn how to use the very fancy unix sort function.\nWe want to split the data in chunks, one chunk for each symbol. It is a lot easier to do once the data is ordered by symbol!\nFirst we pipe the data without the header, then we use sort based on the first column and allow for parallel processing. The one thing to watch for is memory usage (this will eat pretty much of all your memory and get your job killed if you don\u0026rsquo;t watch it). So we define an upper bound for memory usage. Given the memory allocation defined above, we restrict sort to only use 80% of it:\nmem_for_sort=$(echo \u0026#34;${mem_alloc%G} * 0.8 / 1\u0026#34; | bc) # bc is the bash calculator /usr/bin/time tail -n +2 $TAQ_HOME/taq_select.csv | \\ sort -t, -k1,1 --buffer-size=\u0026#34;${mem_for_sort}G\u0026#34; --parallel=$nprocs --temporary-directory=$TAQ_HOME \u0026gt; $TAQ_HOME/taq_sorted.csv This can take a while. I have waited close to one hour for the largest files (128 cores, 490Gb of memory allocated).\nNote: you can clean up the non sorted file to save a little bit of space at this stage rm $TAQ_HOME/taq_select.csv\nSplit the data # Last of the preprocessing, we split the data in chunks: one chunk for each symbol/stock. Given the sorted nature of the data, this is a straightforward (I only spent a day figuring it out using chatGPT) application of awk\nFirst we make some room for the chunks by giving them their own directory\nTAQ_CHUNKS=\u0026#34;$TAQ_HOME/chunks/\u0026#34; mkdir -p $TAQ_CHUNKS Then we process the whole thing using awk\ncat $TAQ_HOME/taq_sorted.csv | \\ awk -v chunkDir=\u0026#34;$TAQ_CHUNKS\u0026#34; -F, \u0026#39; { if (last != $1) { if (last != \u0026#34;\u0026#34;) close(chunkDir \u0026#34;/chunk_\u0026#34; last \u0026#34;.csv\u0026#34;); last = $1; } print \u0026gt; (chunkDir \u0026#34;/chunk_\u0026#34; $1 \u0026#34;.csv\u0026#34;); }\u0026#39; The script reads the whole file line by line; it checks the first column (the \u0026ldquo;SYMBOL\u0026rdquo; column), if it is equal to the first column of the previous line, it appends the line to the file, if not it moves to create a new file. The created files are named based on the first column.\nThis process is sequential and can be quite slow (close to one hour for the largest file).\nProcessing of stock specific statistics in julia # We have close to 10,000 files in $TAQ_CHUNKS ready to be read one by one and processed. For this we are going to do some standard data processing in julia \u0026mdash; I compute OIB here, but this would for everything else that is at the stock-level.\nIf you have access to multiple cores, it makes sense to process this in paralle. It is fairly easy to implement; you still need to be careful not to trigger segfaults though.\nPreamble # My preamble is pretty standard and only use basic julia DataFrame stuff.\nusing CSV using DataFrames, DataFramesMeta using Dates, PeriodicalDates using Pipe: @pipe import ShiftedArrays: lag using Statistics import StatsBase: std @info Threads.nthreads() # usefule for parallelism later on # To ingest the command line parameter I pass to the script datey = ARGS[1] TAQ_CHUNKS = ARGS[2] # TAQ_CHUNKS=\u0026#34;/scratch.global/eloualic/taq/chunks\u0026#34; We are going to process each symbol one by one and store the statistics in a table.\nfile_list=readdir(TAQ_CHUNKS); n_files = length(file_list) df_oib_vol_array = Vector{Union{DataFrame, Nothing}}(nothing, n_files); Threads.@threads for i_f = 1:n_files # read the file for one stock df_taq_symbol = ingest_file(\u0026#34;$TAQ_CHUNKS/$file_in\u0026#34;; verbose=verbose) # create the trade sign flag df_taq_symbol = create_trade_sign!(df_taq_symbol) # create the order imbalance statistic df_oib = create_oib(df_taq_symbol) # get the volatility of the order imbalance df_oib_vol_array[i_f] = create_oib_vol(df_oib) end The most important step is how we read the file. Since this is happening inside a parallel loop, we need to make sure CSV.read only happens on a single thread.\nfunction read_file(file_in::AbstractString; verbose=false) df_taq_symbol = CSV.read(file_in, DataFrame, header=false, ntasks=1); rename!(df_taq_symbol, [:symbol, :date, :time, :price, :size]); end Next we follow Chordia et al. to estimate whether the trade is a buy or a sell order. Basically we compare the current price to previous prices (up to a lag of 5). This is the step that is the slowest when working with the whole dataset at a time.\nfunction create_trade_sign!(df_taq_symbol::DataFrame) @transform!(groupby(df_taq_symbol, :symbol), :l1_price=lag(:price), :l2_price=lag(:price, 2), :l3_price=lag(:price, 3), :l4_price=lag(:price, 4), :l5_price=lag(:price, 5)); @rtransform! df_taq_symbol @passmissing :trd_sgn = :price \u0026gt; :l1_price ? 1 : :price \u0026lt; :l1_price ? -1 : :price \u0026gt; :l2_price ? 1 : :price \u0026lt; :l2_price ? -1 : :price \u0026gt; :l3_price ? 1 : :price \u0026lt; :l3_price ? -1 : :price \u0026gt; :l4_price ? 1 : :price \u0026lt; :l4_price ? -1 : :price \u0026gt; :l5_price ? 1 : :price \u0026lt; :l5_price ? -1 : missing return df_taq_symbol end The other two functions are fairly straightforward and not particularly interesting\nfunction create_oib(df) #; to::TimerOutput=to) symbol_var=df[1,:symbol] dropmissing!(df, :trd_sgn) nrow(df)==0 \u0026amp;\u0026amp; return DataFrame(symbol=symbol_var, date=missing) # some do not have valid signed trades df_oib = @combine(groupby(df, [:date,:trd_sgn]), :oib_shr_sign=sum(:size), :oib_num_sign=length(:size)) |\u0026gt; (d -\u0026gt; @transform!(groupby(d, :date), :oib_shr_tot=sum(:oib_shr_sign), :oib_num_tot=sum(:oib_num_sign)) ) @transform!(groupby(df_oib, :date), :oib_shr_ratio=sum(:trd_sgn .* :oib_shr_sign) ./:oib_shr_tot, :oib_num_ratio=sum(:trd_sgn .* :oib_num_sign) ./:oib_num_tot, :symbol=symbol_var) return df_oib end function create_oib_vol(df) #; to::TimerOutput=to) symbol_var=df[1,:symbol] dropmissing!(df, :date) nrow(df)==0 \u0026amp;\u0026amp; return DataFrame(symbol=symbol_var, datem=missing, oib_shr_vol=missing, oib_num_vol=missing) df_oib_vol = unique(@rselect(df, :date, :datem=MonthlyDate(:date), :symbol, :oib_shr_ratio, :oib_num_ratio)) |\u0026gt; (d -\u0026gt; @combine(groupby(d, [:symbol, :datem]), :oib_shr_vol=std(:oib_shr_ratio), :oib_num_vol=std(:oib_num_ratio)) ) return df_oib_vol end I don\u0026rsquo;t run the code interactively (see the arguments passed above). The command I pass reads:\n$ julia -t $nprocs import_taq_chunks.jl $DATEY $TAQ_CHUNKS \u0026amp;\u0026gt; import_taq_chunks.log.jl SLURM Specifics # If you are running on the job on a cluster with the slurm scheduler, I have attached the commands I have used to make my life easier.\nChordia, Roll, Subrahmanyam (2002): Order imbalance, liquidity, and market returns, Journal of Financial Economics: 65\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI could not find the relevant postgres database for the product, so I processed everything through webqueries. The product is taq_common, library is taq, and file is ct.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ns5cmd is faster than s3cmd, but in the grand scheme of things here this is not going to matter very much.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI tried installing the more recent qsv but could not compile it properly on the Minnesota Supercomputing Institute MSI cluster.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":1,"href":"/www/blog/posts/2024-03-ST-and-Julia/","title":"Sublime Text and Julia IDE","section":"Blog","content":"Sometimes, I am asked how to set up a simple julia IDE for people who are already using Sublime Text. It is simple in theory but many things can go wrong, so I thought this document could be useful.\nI try to provide step by step instructions as much as possible. Feel free to email me if some of the steps were not as clear as you would have liked.\nN.B.\nThere might be better ways to have a julia IDE (see VSCode with LSP). I happen to like Sublime, it is simpler and faster than VSCode (but I am also an emacs person). Also note that the same thing would apply for R (just change a few paths here and there). This guide was written on 2024-03-xx for Sublime Text 4 and julia 1.10.1\n1. Prerequisite # The \u0026ldquo;required\u0026rdquo; software for this guide are: julia, Sublime Text, and a Terminal application called iterm2.\nFirst, I would recommend to install (optional but recommended) a nicer terminal application than the built-in macos terminal:\nDownload iterm2.\nThis is not strictly necessary but iterm2 has some nice feature that make it work nicely with the Sublime setup here. There are other good terminal applications for macos (e.g. kitty) but I am not as familiar with those. Open the iterm2 application which should be in the application folder (note I will use the words iterm2 and the terminal interchangeably (technically they are not quite the same thing but it won\u0026rsquo;t matter). Download Sublime Text 4 and follow the instructions to install.\nDownload julia and follow the instructions to install.\nAs I am writing this, you can use juliaup to install julia by copying and pasting in your terminal the following: curl -fsSL https://install.julialang.org | sh This allows you to keep your version of julia up to date (this might be a bad thing if you have old code and are not templating packages) Or (simpler imho) download the latest current stable release and install it depending on your platform For example for macos with Apple Silicon download the dmg and install it in your application folder 2. Getting julia to work! # 2.1 Basic installation # If julia is in your application folder, there are two ways to start a julia session.\nDouble click on the julia icon: this opens the macos terminal application (not iterm2) and starts julia Open the terminal (I am assuming iterm2 from now on) and type or paste the path of the julia application binary. For julia 1.10.1 the binary will likely at /Applications/Julia-1.10.app/Contents/Resources/julia/bin/julia If you are working with version 1.XX (where XX is a different number) the path will likely be /Applications/Julia-1.XX.app/Contents/Resources/julia/bin/julia 2.2 Adding julia to your path # Do you need it? # If you have installed julia using juliaup (see section 1 above), the julia application was automatically added to your PATH.1 I believe this means the next step is not necessary. To see whether you should skip the next step type julia inside of iterm2. If julia opens, you are in business, skip 2.2 and go to section 3. If there is some error or julia does not open, follow the instructions in the next section 2.2.\nAdding julia to the path # Typing the full julia path can get annoying pretty quickly, so we will add the directory to the PATH for the terminal (technically for the shell). To make this permanent we are going to edit a special file which is read everytime you start your terminal.\nOn macos the file is .zshrc since the default shell is zsh; this is a configuration file. On other machine the file might be .bashrc if your default shell is bash.\nTo edit this file we need a text editor. Any will do; for example you could use textedit and enter the following at the terminal: open -a TextEdit ~/.zshrc This tells textedit to open the zsh configuration file which is located on your home directory under ~2 You could also use Sublime Text that you just opened; the following should work if it installed properly in the Applications folder: /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl ~/.zshrc\nNow we need to edit this file by adding julia to the path. We can simply add this line:\nexport PATH=$PATH:/Applications/Julia-1.10.app/Contents/Resources/julia/bin This concatenates your path with what was already in it ($PATH) and the directory where the julia binary is. If you are working with a version different than 1.10 then adjust the line for 1.XX as: export PATH=$PATH:/Applications/Julia-1.XX.app/Contents/Resources/julia/bin\nSave the file. Close the window. Restart the terminal (iterm2). Now you should be able to start julia in the terminal by typing julia from anywhere.\n3. Getting Sublime Text to play nice with julia # Sublime text is an editor that relies on packages for added functionality. So next, we will download the necessary packages to get a setup that will let you work with julia from sublime text.\n3.1. Installing Sublime packages # First install the package that can install other packages: that is package control. The instructions to install it are:\nOpen the command palette (cmd+shift+p on macos) Type Install Package Control, press enter Then install the Julia-sublime package similary:\nOpen the command palette (cmd+shift+p on macos) Type Package Control: Install, press enter Then a dropdown menu will show and type julia to search for the julia package, type enter to install it. Last install the SendCode package\nOpen the command palette (cmd+shift+p on macos) Type Package Control: Install, press enter Then a dropdown menu will show and type SendCode to search for the SendCode package, type enter to install it. 3.2 Setting up Sublime packages # Settings of SendCode Open the settings of sendcode: open the command palette (cmd+shift+p on macos), type SendCode settings, and enter You should be dropped into a new window with two files (one on each side). Edit the one on the right which is the one with your personal settings (the one on the left has the general settings). Its name is SendCode.sublime-settings. If you are working with iterm2 copy and paste the following: { \u0026#34;auto_advance\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, \u0026#34;julia\u0026#34;: { \u0026#34;bracketed_paste_mode\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, }, \u0026#34;r\u0026#34;: { \u0026#34;bracketed_paste_mode\u0026#34;: true, \u0026#34;prog\u0026#34;: \u0026#34;iterm\u0026#34;, }, } Keybindings SendCode Open the settings of sendcode: open the command palette (cmd+shift+p on macos), type SendCode key bindings, and enter You should be dropped into a new window with two files (one on each side). Edit the one on the right which is the one with your personal settings (the one on the left has the general settings). This time do not remove existing keybindings as they might be useful stuff. You should add the following to make sure sending lines or highlighted content to be sent to iterm2. { \u0026#34;keys\u0026#34;: [\u0026#34;super+enter\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;send_code\u0026#34;, \u0026#34;context\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;selector\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;equal\u0026#34;, \u0026#34;operand\u0026#34;: \u0026#34;source\u0026#34; } ] }, { \u0026#34;keys\u0026#34;: [\u0026#34;ctrl+enter\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;send_code\u0026#34;, \u0026#34;context\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;selector\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;equal\u0026#34;, \u0026#34;operand\u0026#34;: \u0026#34;source\u0026#34; } ] }, Feel free to change the key bindings for example if you want Cmd-s to send to iterm2 you would replace \u0026ldquo;super+enter\u0026rdquo; by \u0026ldquo;super+s\u0026rdquo;. You should be good to go. Create a test.jl file. Open a terminal session and start julia on the side. select 1+1 in sublime text and press Cmd+Enter at the same time. It should be sending to the terminal.\nYour path is essentially a set of places where the terminal looks for software. So if the directory of julia gets added to the path, the terminal is aware of the julia application and you can type directly $ julia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n~ represents what is known as your home directory. The actual address is /Users/yourname/. You can find it by doing in the terminal: cd ~ to change directory to the home directory, and then pwd to print the directory you are currently in.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"}]